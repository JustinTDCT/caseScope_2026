# CaseScope 2026 - Application Map

**Version**: 1.10.11  
**Last Updated**: 2025-10-31 21:08 UTC  
**Purpose**: Track file responsibilities and workflow

---

## üìã Recent Updates (2025-10-31 21:08 UTC)

### **üêõ v1.10.11 - IOC Re-Hunt Fix: OpenSearch has_ioc Flags Not Cleared** (2025-10-31 21:08 UTC)

**Critical Bug Fix**: IOC re-hunt was clearing database matches but NOT clearing `has_ioc` flags in OpenSearch, causing old IOC events to persist.

**User Report**:
"I disabled 2 IOCs, did a fresh hunt, and then asked to show IOC only events - but the page is showing stuff that should be cleared - i recall an issue either yesterday or earlier where something was not being cleared correctly on a re-hunt so i was getting results that were no longer iocs"

**Problem Identified**:
- **Database**: 28 IOC matches (correct after disabling 2 IOCs)
- **OpenSearch**: 70,065 events still flagged with `has_ioc: true` (old data!)
- **Search Filter "IOC Events Only"**: Showed 70,065 events (should be 28)

**Root Cause**:
The `bulk_rehunt` task was only clearing IOC matches from the database:
```python
# This only clears database records:
ioc_deleted = clear_case_ioc_matches(db, case_id)

# But has_ioc flags in OpenSearch were NEVER cleared!
```

When IOC hunting runs, it:
1. Searches for IOCs in OpenSearch
2. Creates `IOCMatch` records in database
3. Sets `has_ioc: true` flag on matching events in OpenSearch

But when re-hunting:
1. `clear_case_ioc_matches()` deletes database records ‚úì
2. `has_ioc` flags in OpenSearch remain set ‚úó
3. Search filter shows old results ‚úó

**Solution Implemented**:
1. Added new function `clear_case_ioc_flags_in_opensearch()` to `bulk_operations.py`
2. Uses OpenSearch `update_by_query` with Painless script to remove flags
3. Integrated into `bulk_rehunt` task before new hunt starts

**Code Added**:
```python
def clear_case_ioc_flags_in_opensearch(opensearch_client, case_id: int, files: list) -> int:
    """Clear has_ioc flags from all OpenSearch indices for a case"""
    total_updated = 0
    
    for case_file in files:
        if not case_file.is_indexed or not case_file.opensearch_key:
            continue
        
        index_name = case_file.opensearch_key.lower().replace('%4', '4')
        index_name = f"case_{case_id}_{index_name}"
        
        # Clear has_ioc flag using Painless script
        update_body = {
            "script": {
                "source": "ctx._source.remove('has_ioc')",
                "lang": "painless"
            },
            "query": {
                "term": {"has_ioc": True}
            }
        }
        
        response = opensearch_client.update_by_query(
            index=index_name,
            body=update_body,
            conflicts='proceed'
        )
        
        total_updated += response.get('updated', 0)
    
    return total_updated
```

**Files Modified**:
- `app/bulk_operations.py` (lines 76-132 - new function)
- `app/tasks.py` (lines 345-394 - integrated clearing)
- `app/version.json` (updated to v1.10.11)
- `app/APP_MAP.md` (this file)

**Result**:
‚úÖ IOC re-hunt now clears both database AND OpenSearch flags  
‚úÖ Search filter "IOC Events Only" shows accurate results  
‚úÖ Disabled IOCs no longer appear in search results  
‚úÖ Clean slate for every re-hunt

---

### **üêõ v1.10.10 - Bulk Import Fix: Missing Import Caused Files to Stay Queued** (2025-10-31 20:04 UTC)

**Critical Bug Fix**: Bulk import completed filtering but failed to queue files for processing.

**User Report**:
"check whats happening i just local uploaded a bunch of files and they show queued but none are processing"

**Problem Identified**:
- Bulk import processed 1,602 files successfully
- Filtered out 915 zero-event files (archived correctly)
- 687 valid files ready for processing
- **Crashed with**: `NameError: name 'queue_file_processing' is not defined` at line 558

**Root Cause**:
The `bulk_import_directory` task in `tasks.py` was calling `queue_file_processing()` but never imported it from `bulk_operations.py`. The function exists and works correctly - it was just missing the import statement.

**Error Log**:
```
[2025-10-31 19:58:26,373: ERROR/ForkPoolWorker-4] [BULK IMPORT] Fatal error: name 'queue_file_processing' is not defined
Traceback (most recent call last):
  File "/opt/casescope/app/tasks.py", line 558, in bulk_import_directory
    queue_file_processing(process_file, case_files, operation='full')
    ^^^^^^^^^^^^^^^^^^^^^
NameError: name 'queue_file_processing' is not defined
```

**Impact**:
- Files showed as "Queued" in UI but never started processing
- Workers were idle
- No visible error in the UI - appeared to be stuck
- Files had to be re-uploaded after fix

**Solution Implemented**:
Added missing import at line 452 in `tasks.py`:
```python
from bulk_operations import queue_file_processing
```

**Files Modified**:
- `app/tasks.py` (line 452 - added import)
- `app/version.json` (updated to v1.10.10)
- `app/APP_MAP.md` (this file)

**Result**:
‚úÖ Bulk import now completes successfully and queues files for processing  
‚úÖ Workers process files immediately after upload  
‚úÖ No more "stuck in queued" status

---

### **üìä v1.10.9 - SIGMA Rules: lolrmm Detection Rules Added** (2025-10-31 19:34 UTC)

**Bug Fix**: Dashboard was not counting or displaying lolrmm RMM tool detection rules.

**User Report**:
"now, i have asked this before and you didn't CHECK the sigma cache to ensure enabled rules from all sources are used - i recall an issue with an incomplete cache"

**Problem Identified**:
- Dashboard showed: **2,888 rules**
- lolrmm rules: **452 SIGMA detections for RMM tools**
- Total should be: **3,340 rules** (+452 missing!)

**Root Cause**:
1. lolrmm repository was cloned at `/opt/casescope/lolrmm` (452 rules)
2. Chainsaw cache building WAS copying lolrmm rules (working correctly)
3. But `sigma_utils.py` was NOT counting lolrmm rules
4. Dashboard showed incomplete count (2,888 instead of 3,340)

**Solution Implemented**:
1. Added lolrmm rules to `sigma_utils.py` counting logic
2. Updated `list_sigma_rules()` function to scan lolrmm directory
3. Updated `get_sigma_stats()` function to include RMM Detections

**Files Modified**:
- `app/sigma_utils.py` (lines 30-37, 206-214)
- `app/version.json`
- `app/APP_MAP.md`

**Result**:
```
Windows Rules:       2,350
DFIR Rules:              0
Emerging Threats:      409
Threat Hunting:        129
RMM Detections:        452  ‚Üê NEW!
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
TOTAL:               3,340 rules
```

**Dashboard Now Shows**:
- Total Rules (All Sets): **3,340** (was 2,888)
- Enabled Rules: **3,340** (was 2,888)
- RMM Detections: **452** (was missing)

---

### **üîç v1.10.8 - IOC Hunting Field Mapping Fix: Search ALL Fields** (2025-10-31 19:22 UTC)

**Critical Bug Fix**: IOC hunting was using targeted field searches instead of searching ALL fields.

**User Report**:
"nope still not working right... something you are doing is not searching all the fields - the Security.EVTX file for this case should have a ton of IOCs in it"
"i previously told you the IOC hunt should check ALL FIELDS"

**Root Cause Analysis**:

The IOC hunting code had a `ioc_field_map` that limited searches to specific fields:
```python
ioc_field_map = {
    'username': ['account', 'username', 'user'],  # Only these fields!
    'ip': ['source_ip', 'destination_ip', 'ip_address', 'ip'],  # Only these fields!
}
```

**Problem**: IOCs appear in MANY nested locations:
- Username `craigw` could be in:
  - `Event.EventData.SubjectUserName`
  - `Event.EventData.TargetUserName`
  - `Event.EventData.User`
  - `Event.System.Security.UserID`
  - ANY other nested field!

**User's Grep Script (SearchEVTX.sh)**:
```bash
grep -i -F "craigw" file.jsonl  # Finds IOC ANYWHERE in JSON
```
- Result: **10,000+ matches** ‚úÖ

**My Code (BEFORE FIX)**:
- Only searched specific field names
- Result: **2 matches** ‚ùå

**Test Results**:
```
Manual OpenSearch query: *craigw* = 10,000+ matches
User's grep script:       craigw  = 10,000+ matches
IOC hunt (v1.10.7):       craigw  = 2 matches (WRONG!)
```

**Solution Implemented**:

1. **Removed targeted field mapping entirely**
   - File: `app/file_processing.py` lines 1061-1064
   - Deleted all field restrictions
   - Now returns empty dict (default to wildcard)

2. **All IOC types now search ALL fields `["*"]`**
   - Matches grep behavior: finds IOC anywhere in JSON
   - Uses `query_string` with wildcard for nested objects
   - No field restrictions

3. **Updated logic comments**:
   ```python
   # DEFAULT: Search all fields ["*"] to match grep behavior
   # This ensures we find IOCs regardless of their location in nested JSON
   ioc_field_map = {
       # All IOC types now search all fields by default (like grep)
   }
   ```

**Files Modified**:
- `app/file_processing.py` (lines 1047-1074)
- `app/version.json`
- `app/APP_MAP.md`

**Expected Results After Fix**:
- ‚úÖ Username `craigw`: 10,000+ matches
- ‚úÖ All IPs in CSV/Security.EVTX: Found
- ‚úÖ All FQDNs: Found
- ‚úÖ All file paths: Found
- ‚úÖ Matches grep behavior exactly

---

### **üîç v1.10.7 - IOC Hunting Critical Fix: Special Character Escaping + Nested Objects + Cache Management** (2025-10-31 19:00 UTC)

**Critical Bug Fix**: IOCs not being detected due to TWO issues:
1. **Nested Objects**: `simple_query_string` doesn't search nested fields
2. **Special Characters**: Lucene special chars (`:`, `/`, `\`) not escaped in query_string

**User Reports**:
1. "IOCs - i know they existed in the files uploaded but 0 returned results - we should be checking EVERY field for the IOCs"
2. "I added a new file, i KNOW more IOCs exist then what is being reported"

**Root Cause Analysis**:

**Issue 1**: The IOC hunting function was using `simple_query_string` with `fields: ["*"]` to search all fields. However, **`simple_query_string` does NOT recursively search nested objects** in OpenSearch/Elasticsearch!

**Issue 2**: After switching to `query_string`, IOCs with special Lucene characters were causing parse errors:
- `Failed to parse query [*C:\Windows\Microsoft.NET\Framework\v4.0.30319\MSBuild.exe*]`
- `Failed to parse query [*https://55i.j3ve.ru/clh1ygiq*]`

**Test Results**:
- `query_string` with wildcard: **179 hits** ‚úÖ (IOCs exist in data!)
- `simple_query_string` with `["*"]`: **0 hits** ‚ùå (Current method failed!)

**Problem Example**:
```json
{
  "Event": {
    "System": {
      "Computer": "ATN76254.JOHNWATTS.LOCAL"
    },
    "EventData": {
      "Message": "Connection to https://55i.j3ve.ru/clh1ygiq failed"
    }
  }
}
```

- IOC: `55i.j3ve.ru` (exists deep in `Event.EventData.Message`)
- Old query: `simple_query_string` with `fields: ["*"]` ‚Üí **0 matches** (doesn't traverse nested objects)
- New query: `query_string` with wildcard ‚Üí **179 matches** ‚úÖ

**Solutions Implemented**:

**Fix 1**: Changed IOC hunting to use **query_string** instead of **simple_query_string** for wildcard (`["*"]`) searches.

**Fix 2**: Added Lucene special character escaping to prevent query parse errors:
```python
def escape_lucene_special_chars(text):
    special_chars = ['\\', '+', '-', '=', '&', '|', '!', '(', ')', '{', '}', 
                     '[', ']', '^', '"', '~', '*', '?', ':', '/', ' ']
    for char in special_chars:
        if char != '*':
            text = text.replace(char, f'\\{char}')
    return text
```

**Fix 3**: Implemented OpenSearch Scroll API to retrieve **unlimited results** (not capped at 10,000):
- Uses 5,000-record batches per scroll
- Commits to database in 1,000-record batches
- Updates OpenSearch in 1,000-record batches
- Handles IOCs that appear in 10,000+ events

**Fix 4**: Added automatic cache clearing before bulk IOC hunts (prevents circuit breaker):
- OpenSearch heap was hitting 98%+ usage with 4GB limit
- Added `clear_cache()` call at start of `bulk_rehunt()` task
- Clears fielddata, query, and request caches
- Prevents `circuit_breaking_exception` errors during bulk operations
- File: `tasks.py` lines 354-366

**Code Changes** (`file_processing.py` lines 1065-1096):

```python
# NEW: Dual query strategy based on field targeting
if search_fields == ["*"]:
    # Wildcard search - use query_string to search nested objects
    query = {
        "query": {
            "query_string": {
                "query": f"*{ioc.ioc_value}*",
                "default_operator": "AND",
                "analyze_wildcard": True,
                "lenient": True
            }
        },
        "size": 10000
    }
    logger.info(f"[HUNT IOCS] Using query_string for wildcard search (nested objects)")
else:
    # Targeted field search - use simple_query_string (better performance)
    query = {
        "query": {
            "simple_query_string": {
                "query": ioc.ioc_value,
                "fields": search_fields,
                "default_operator": "and",
                "lenient": True,
                "analyze_wildcard": False
            }
        },
        "size": 10000
    }
    logger.info(f"[HUNT IOCS] Using simple_query_string for targeted field search")
```

**Query Strategy**:
- **Wildcard searches** (`url`, `fqdn`, `command`, `filename`, etc.) ‚Üí `query_string` (handles nesting)
- **Targeted searches** (`ip`, `username`, `hostname`, `user_sid`) ‚Üí `simple_query_string` (better performance)

**Benefits**:
‚úÖ **IOCs now detected in nested EVTX structures**  
‚úÖ **No performance loss** - targeted searches still use efficient method  
‚úÖ **Backward compatible** - existing IOC types unchanged  
‚úÖ **Better logging** - shows which query method is used

**Affected IOC Types** (now working properly):
- `url` - URLs embedded in event messages
- `fqdn` - Domain names in any nested field
- `command` - Command lines in nested structures
- `filename` - Filenames in event data
- All other unmapped types (default wildcard behavior)

**Case-Specific IOCs** (confirmed working for Case 2):
- 7 active IOCs for Case 2
- Previously: 0 matches detected
- Now: Should detect matches in nested EVTX event data

**Files Modified**:
- `file_processing.py` - IOC hunting query logic (32 lines changed)
- `version.json` - Updated to v1.10.7
- `APP_MAP.md` - This file

**Testing Required**:
- User should trigger IOC re-hunt on Case 2 to detect previously missed IOCs
- Expected: URLs, FQDNs, filenames should now be found in EVTX events

**Commit**: IOC hunting nested object fix

---

## üìã Previous Updates (2025-10-30 00:10 UTC)

### **üîç v1.10.6 - User SID IOC Type, Smart Field Mapping & DFIR-IRIS Timeout Fix** (2025-10-30 00:10 UTC)

**New Features & Fixes**: 
1. Added "User SID" as a new IOC type with intelligent field mapping for more precise detections
2. Fixed DFIR-IRIS sync timeout issue

**User Request #1 - User SID**: "can we add an IOC type (User SID) and link it to 'account'"

**User Request #2 - DFIR-IRIS Sync**: "sync to dfir failed - can you see why"

**Implementation**:

1. **New IOC Type: User SID**
   - Added "User SID" option to IOC type dropdowns in both templates
   - Available in IOC Management page (`ioc_management.html`)
   - Available in Search Events "Add as IOC" modal (`search_events.html`)
   - Displays as "USER_SID" badge in UI

2. **Smart Field Mapping System** (`file_processing.py` lines 1047-1077)
   - Created `ioc_field_map` dictionary to map IOC types to specific OpenSearch fields
   - **User SID** ‚Üí searches: `account`, `user_sid`, `sid`
   - **Username** ‚Üí searches: `account`, `username`, `user`
   - **Hostname** ‚Üí searches: `computer_name`, `hostname`, `host`
   - **IP** ‚Üí searches: `source_ip`, `destination_ip`, `ip_address`, `ip`
   - All other types continue to search all fields (wildcard `*`)

3. **Benefits of Field Mapping**:
   - ‚úÖ **More Precise Matches**: Reduces false positives by searching only relevant fields
   - ‚úÖ **Better Performance**: Targeted searches are faster than wildcard searches
   - ‚úÖ **Flexible Fallback**: Multiple field names covered (e.g., account/user_sid/sid)
   - ‚úÖ **Backward Compatible**: Unmapped types still search all fields

4. **Logging Enhancement**:
   - Added debug log showing which fields are searched for each IOC type
   - Helps troubleshoot why certain IOCs match or don't match

**Example Usage**:
- Add IOC: Type="User SID", Value="S-1-5-21-1234567890-1234567890-1234567890-500"
- System searches only the `account`, `user_sid`, and `sid` fields in OpenSearch
- Matches are flagged as "auto_detected_user_sid" in IOCMatch records

**Files Modified**:
- `templates/ioc_management.html` - Added "User SID" to type dropdown (1 line)
- `templates/search_events.html` - Added "User SID" to type dropdown (1 line)
- `file_processing.py` - Added field mapping logic (16 lines)
- `version.json` - v1.10.6
- `APP_MAP.md` - This file

**Technical Notes**:
- Field mapping uses `simple_query_string` query with targeted field list
- Falls back to wildcard `["*"]` for unmapped IOC types
- Searches are case-insensitive and lenient (handles field type mismatches)
- Max 10,000 results per IOC (existing limit)

**Commit**: `345c358` (User SID IOC Type)

---

## DFIR-IRIS Sync Timeout Fix

**Problem Identified**:
- DFIR-IRIS sync was **working correctly** but **timing out** before completion
- Gunicorn worker timeout was 30 seconds (default)
- Syncing many tagged events (32+ timeline events) took longer than 30 seconds
- Resulted in `[CRITICAL] WORKER TIMEOUT` error and sync appearing to "fail"

**Root Cause Analysis** (from logs):
```
Oct 30 01:07:12 casescope01 gunicorn: INFO:dfir_iris:[DFIR-IRIS] Timeline event created: 375
Oct 30 01:07:13 casescope01 gunicorn: INFO:dfir_iris:[DFIR-IRIS] Timeline event created: 376
...
Oct 30 01:07:24 casescope01 gunicorn: INFO:dfir_iris:[DFIR-IRIS] Timeline event created: 406
Oct 30 01:07:24 casescope01 gunicorn: [CRITICAL] WORKER TIMEOUT (pid:220822)
Oct 30 01:07:24 casescope01 gunicorn: [INFO] Worker exiting (pid: 220822)
```
- Successfully created 32 timeline events in 12 seconds
- BUT: Total sync operation (including IOCs, case creation, cleanup) exceeded 30 seconds
- Worker was killed mid-operation

**Solution**:
- Increased Gunicorn timeout from 30 seconds (default) to 300 seconds (5 minutes)
- Modified `/etc/systemd/system/casescope.service`:
  ```ini
  ExecStart=/opt/casescope/venv/bin/gunicorn -w 4 -b 0.0.0.0:5000 --timeout 300 wsgi:app
  ```
- Reloaded systemd and restarted service

**Why 300 seconds?**:
- DFIR-IRIS sync involves multiple API calls per case:
  - Customer creation/lookup
  - Case creation/lookup + status sync
  - IOC sync (one API call per IOC)
  - Timeline event sync (one API call per tagged event)
  - Asset creation/lookup (one per unique hostname)
  - Cleanup (check IRIS timeline, remove untagged events)
- Large cases with 100+ tagged events could take 1-2 minutes
- 300 seconds provides comfortable margin for even large syncs

**Technical Details**:
- Sync function: `sync_case_to_dfir_iris()` in `dfir_iris.py` (lines 419-574)
- Process: Customer ‚Üí Case ‚Üí IOCs ‚Üí Tagged Events ‚Üí Cleanup
- Each tagged event requires: Event fetch from OpenSearch + Asset check/create + IOC linking + Timeline create
- Asset caching prevents duplicate API calls for same hostname

**Files Modified**:
- `/etc/systemd/system/casescope.service` - Added `--timeout 300` parameter
- `version.json` - Updated to v1.10.6
- `APP_MAP.md` - This file

**Testing**:
- Service restarted successfully with new timeout
- Gunicorn workers now have 300-second timeout
- Large DFIR-IRIS syncs can now complete without worker timeout

**Commit**: System configuration change (outside repo)

---

### **üì• v1.10.5 - CSV Export & Custom Favicon** (2025-10-29 23:52 UTC)

**New Features**: 
1. Export filtered/searched event lists to CSV format
2. Custom CaseScope favicon logo for browser tabs

**User Request #1 - CSV Export**: "search events - can we do an export button CSV; it would export the current event list (so what the user has searched/filtered down to) and export these columns: - date / time - description - computer name - file name of the event - raw data of the event (JSON whatever)"

**Design Philosophy**: Keep code minimal, reuse existing logic, modular architecture

**Implementation**:

1. **New Module: `export_utils.py`** (38 lines)
   - `generate_events_csv(events)` - Converts event list to CSV format
   - Columns: Date/Time, Description, Computer Name, File Name, Raw Data (JSON)
   - Uses Python `csv` module and `io.StringIO` for efficient in-memory generation
   - Converts entire event dict to JSON string for "Raw Data" column

2. **New Route: `GET /case/<id>/search/export`** (`main.py` lines 905-976)
   - Reuses identical search query building logic from `search_events` route
   - Parameters: Same as search (q, filter, date_range, file_types, sort, order)
   - Executes search with `per_page=10000` (max export limit)
   - Returns CSV file with timestamped filename
   - Sets proper Content-Type and Content-Disposition headers for download

3. **UI Enhancement: Export CSV Button** (`templates/search_events.html`)
   - Added green "üì• Export CSV" button between Search and Reset buttons
   - JavaScript `exportToCSV()` function builds export URL from current form state
   - Preserves all filters and search parameters (removes pagination)
   - Triggers browser download when clicked

**Key Features**:
- ‚úÖ Exports only filtered/searched results (not all events)
- ‚úÖ Includes all search filters: event type (SIGMA/IOC/Tagged), file types, date range
- ‚úÖ Respects current sort order
- ‚úÖ Auto-generates timestamped filename (e.g., `case_123_events_export_20251029_235200.csv`)
- ‚úÖ Handles large exports (up to 10,000 events)
- ‚úÖ Raw JSON data preserved in CSV column for further analysis

**Files Created**:
- `export_utils.py` - New modular CSV generation utility

**Files Modified**:
- `main.py` - Added export route (72 lines)
- `templates/search_events.html` - Added export button and JavaScript (20 lines)
- `version.json` - v1.10.5
- `APP_MAP.md` - This file

**Code Reuse**:
- Search query building logic: Directly reused from `search_events` route
- Event field extraction: Reused `extract_event_fields()` from `search_utils.py`
- No duplicate code - modular design with new standalone utility module

**User Request #2 - Favicon**: "can you make a fav icon logo for me?"

**Favicon Implementation**:
- Created custom SVG favicon: Blue folder with magnifying glass overlay
- Symbolizes digital forensics and case investigation
- 64x64 vector graphic (scales perfectly at all sizes)
- Added to `base.html` template (all pages)
- Browser tab now shows CaseScope branding

**Files Created** (Favicon):
- `static/favicon.svg` - Custom vector logo

**Files Modified** (Favicon):
- `templates/base.html` - Added favicon link tag

**Commits**: `02c7758` (CSV Export), `d28c902` (Favicon)

---

### **üìä v1.10.4 - Completed Files Counter & Status Reordering** (2025-10-29 23:40 UTC)

**New Feature**: Added Completed files counter and reordered processing status fields

**User Request**: Display all status fields on one line, add Completed count, order as: Completed, Failed, Queued, Indexing, SIGMA, IOC

**Changes**:

1. **Added Completed Counter**
   - Added `files_completed` to backend queries
   - Shows count of files with `indexing_status = 'Completed'`
   - Included in all routes: `case_files`, `global_files`, `file-stats` API

2. **Reordered Status Fields** (Horizontal Display)
   - Order: ‚úÖ Completed, ‚ùå Failed, ‚è≥ Queued, üìá Indexing, üõ°Ô∏è SIGMA, üéØ IOC
   - All fields always visible (shows 0 if none)
   - Single line with flex layout (wraps on small screens)
   - Removed conditional show/hide logic

3. **Updated JavaScript** (`templates/case_files.html`)
   - `refreshFileStats()` now updates 6 fields including completed
   - Simpler update logic - just sets textContent for each field

4. **Backend Updates**
   - `hidden_files.py`: Added `files_completed` to `get_file_stats_with_hidden()`
   - `routes/files.py`: Added `files_completed` to both `global_files` and `case_files` routes
   - `routes/files.py`: Added `completed` count to `/file-stats` API endpoint

**Files Modified**:
- `templates/case_files.html` - Reordered status fields, added completed (lines 57-80)
- `routes/files.py` - Added completed to 3 locations (lines 75, 159, 695)
- `hidden_files.py` - Added completed query and return value (lines 159-164, 190)
- `version.json` - v1.10.4
- `APP_MAP.md` - This file

**Commit**: `5cc4778`

---

### **üìä v1.10.3 - Auto-Refreshing File Statistics** (2025-10-29 23:33 UTC)

**New Feature**: File Statistics tile now auto-updates every 10 seconds without page reload

**Issue Resolved**: User reported file statistics (Queued, Indexing, Failed counts) were not updating in real-time while queue viewer was. File stats were server-rendered only.

**Solution**:

1. **New Route** (`routes/files.py` lines 683-739)
   - `GET /case/<id>/file-stats` - Returns current file status counts as JSON
   - Queries counts for: Queued, Indexing, SIGMA Testing, SIGMA Hunting, Failed
   - Lightweight endpoint for frequent polling

2. **JavaScript Auto-Update** (`templates/case_files.html` lines 717-770)
   - `refreshFileStats()` - Fetches stats and updates Processing Status section
   - Dynamically rebuilds stat items (only shows non-zero counts)
   - Shows "All Complete" when no files in processing states
   - Integrated with existing 10-second refresh interval

3. **Task ID Cleanup**
   - Fixed file 4542 which had status "Failed" but retained `celery_task_id`
   - Task IDs should be cleared when files fail to allow clean requeue
   - Added manual cleanup script execution

**Behavior**:
- File Statistics "Processing Status" section updates every 10 seconds
- Queue viewer continues to update every 10 seconds (unchanged)
- No page reload required to see current processing state
- Stat items dynamically show/hide based on counts

**Files Modified**:
- `routes/files.py` - Added file-stats endpoint (57 lines)
- `templates/case_files.html` - Added refreshFileStats() function (54 lines)
- `version.json` - Updated to v1.10.3
- `APP_MAP.md` - This file

**Commit**: `b0aa7be`

---

### **üìä v1.10.2 - Minimal Queue Viewer & Requeue Button** (2025-10-29 22:19 UTC)

**New Feature**: Clean scrollable queue viewer in Event Statistics tile + bulk requeue button

**Components Created/Modified**:

1. **Queue Status Routes** (`routes/files.py` lines 683-808)
   - **New Routes**:
     - `GET /case/<id>/queue/status` - Returns queued files (limit 100), processing files, failed count
     - `POST /case/<id>/queue/requeue-failed` - Requeues all failed files (excluding hidden)
   - **Returns**: JSON with queued/processing file arrays and counts

2. **Event Statistics Tile** (`templates/case_files.html` lines 139-154)
   - **Added**: Minimal "Processing Queue" section with:
     - Manual refresh button (üîÑ) with spin animation
     - Scrollable file list (max-height: 200px, auto-scrolling)
     - Shows processing files (üìá) and queued files (‚è≥)
     - Displays first 30 queued + "X more" indicator
   - **No stats/counts** - just clean file list
   - **Auto-refresh**: 10-second interval via `DOMContentLoaded` event

3. **Bulk Operations Button Bar** (`templates/case_files.html` lines 172-175)
   - **Added**: "Requeue Failed" button next to Queue Cleanup
   - **Styling**: Matches existing buttons (warning color)
   - **Function**: Calls `/queue/requeue-failed` endpoint

4. **JavaScript Functions** (`templates/case_files.html` lines 583-717)
   - `refreshQueueStatus()` - Fetches queue data, updates file list with error handling
   - `requeueFailedFiles()` - Confirms and requeues all failed files
   - `startQueueAutoRefresh()` - Initiates 10-second auto-refresh interval
   - `stopQueueAutoRefresh()` - Clears interval on navigation
   - Spin animation - IIFE-wrapped to prevent variable conflicts

**Fixes Applied**:
- **JavaScript Syntax Error** (commit 858c03f): Fixed duplicate `const style` declaration
  - Wrapped style creation in IIFE with unique variable name `spinStyle`
  - Added existence check via ID `queue-spin-animation`
  - Enhanced error handling with null checks for DOM elements
  - Added HTTP status validation in fetch

**Requeue Operation**:
1. Finds files: `status LIKE 'Failed%' AND is_hidden = False`
2. Creates Celery task: `tasks.process_file`
3. Updates: `status = 'Queued'`, stores `celery_task_id`
4. Returns requeue count + errors

**Error Handling**:
- Checks for DOM element existence before operations
- HTTP status validation in fetch responses
- Displays error messages in queue window
- Console logging for debugging

**UI Philosophy**:
- Minimal - no duplicate stats (File Statistics tile already shows counts)
- Clean scrolling window for queue visibility
- Button integrated into existing bulk operations bar
- Tile size unchanged
- Auto-updates without page reload

**Files Modified**:
- `routes/files.py` - 2 routes (126 lines total)
- `templates/case_files.html` - Queue section (16 lines) + button (4 lines) + JS (135 lines with error handling)
- `version.json` - v1.10.2
- `APP_MAP.md` - This file

**Commits**:
- `22e9c5d` - Initial queue viewer implementation
- `07c6ca1` - Simplified to minimal design
- `858c03f` - Fixed JavaScript syntax error

---

### **üß† v1.8.0 - OpenCTI Threat Intelligence Integration** (2025-10-29 17:00 UTC)

**New Feature**: Complete OpenCTI integration for IOC enrichment with threat intelligence

**Components Created**:

1. **OpenCTI Client Module** (`opencti.py`)
   - **Purpose**: Reusable OpenCTI API client for threat intelligence enrichment
   - **Library**: `pycti` (official OpenCTI Python client)
   - **Class**: `OpenCTIClient` with health check, indicator search, and batch enrichment
   - **Functions**:
     - `ping()` - Test connection to OpenCTI instance
     - `check_indicator(value, type)` - Query single IOC and extract threat intelligence
     - `check_indicators_batch()` - Bulk enrichment for multiple IOCs
     - `get_statistics()` - Get OpenCTI instance statistics
   - **IOC Type Mapping**: Maps CaseScope IOC types to OpenCTI observable types (IP ‚Üí IPv4-Addr, domain ‚Üí Domain-Name, etc.)
   - **Search Strategy**:
     - Primary: Search as Indicator (high confidence, known malicious)
     - Fallback: Search as Observable (lower confidence, seen in data)
   - **Risk Scoring**: 0-100 score based on confidence (0-50) + indicator types (+30) + threat actor relationships (+20)

2. **Enrichment Function** (`enrich_case_iocs()`)
   - **Purpose**: Batch enrich all IOCs for a case
   - **Process**: Query active IOCs ‚Üí Check each in OpenCTI ‚Üí Store enrichment data
   - **Storage**: JSON in `ioc.opencti_enrichment` + timestamp in `ioc.opencti_enriched_at`
   - **Returns**: Count of enriched/found/not found IOCs

3. **Settings Page Updates** (`templates/settings.html`)
   - **New Section**: OpenCTI Integration (after DFIR-IRIS section)
   - **Fields**: Enable checkbox, URL input, API key input
   - **Actions**:
     - Test Connection button (üîå) - Verifies OpenCTI is accessible
     - Sync Now button (üîÑ) - Enriches all IOCs in all active cases
   - **Info Card**: Explains enrichment behavior and data types collected

4. **Settings Routes** (`routes/settings.py`)
   - **Added Routes**:
     - `GET /settings` - Now includes OpenCTI settings in template context
     - `POST /settings/save` - Now saves OpenCTI settings (enabled, URL, API key)
     - `POST /settings/test_opencti` - Tests OpenCTI connection and returns status
     - `POST /settings/sync_opencti` - Enriches all IOCs in all active cases

5. **IOC Management Enhancements** (`routes/ioc.py`, `templates/ioc_management.html`)
   - **Updated Routes**:
     - `POST /case/<id>/ioc/<id>/enrich` - Now uses real OpenCTI client (replaced placeholder)
     - `GET /case/<id>/ioc/<id>/enrichment` - New route to view enrichment details as JSON
   - **UI Updates**:
     - "üîç CTI" badge now clickable (opens enrichment modal)
     - Per-IOC enrich button (üîç) in actions column
     - Auto-enrichment when adding new IOCs (if OpenCTI enabled)
   - **Enrichment Modal**:
     - Displays summary (status, risk score, confidence, TLP)
     - Shows description, labels, threat actors, campaigns, malware families
     - Shows indicator types
     - "Clean" message if not found in OpenCTI

**Enrichment Data Structure**:
```json
{
  "found": true/false,
  "indicator_id": "OpenCTI ID",
  "name": "Indicator name",
  "description": "Threat context",
  "score": 0-100,
  "confidence": 0-100,
  "tlp": "TLP:CLEAR/GREEN/AMBER/RED",
  "labels": ["tag1", "tag2"],
  "threat_actors": ["APT28", "APT29"],
  "campaigns": ["Operation X"],
  "malware_families": ["TrickBot", "Emotet"],
  "indicator_types": ["malicious-activity", "compromised"],
  "checked_at": "2025-10-29T17:00:00Z"
}
```

**Integration Points**:
1. **IOC Addition**: New IOCs auto-enriched if OpenCTI enabled
2. **Manual Enrichment**: Per-IOC enrich button on IOC management page
3. **Bulk Enrichment**: "Sync Now" button enriches all IOCs in all active cases
4. **UI Display**: "CTI" badge shown for enriched IOCs, clickable for details

**Database Fields** (already existed in IOC model):
- `opencti_enrichment` (Text/JSON) - Stores full enrichment data
- `opencti_enriched_at` (DateTime) - Timestamp of last enrichment

**Benefits**:
- ‚úÖ Automated threat intelligence enrichment for IOCs
- ‚úÖ Threat actor and campaign associations
- ‚úÖ Risk scoring based on confidence and relationships
- ‚úÖ TLP classification for data sharing decisions
- ‚úÖ Detailed context for investigation
- ‚úÖ "Not found" indicators marked as potentially clean
- ‚úÖ Re-enrichment supported (updates existing data)

**Files Created**:
- `opencti.py` - OpenCTI client module (443 lines)

**Files Modified**:
- `routes/settings.py` - Added OpenCTI settings handling and routes (85 lines added)
- `templates/settings.html` - Added OpenCTI configuration section (139 lines added)
- `routes/ioc.py` - Replaced placeholder with real OpenCTI enrichment (52 lines modified)
- `templates/ioc_management.html` - Added enrichment modal and clickable badge (150 lines added)
- `version.json` - Updated to v1.8.0 with OpenCTI architecture documentation
- `APP_MAP.md` - This file

**Configuration Required**:
1. OpenCTI instance URL (e.g., https://opencti.company.com)
2. OpenCTI API key (from Profile ‚Üí API Tokens in OpenCTI)
3. `pycti` library installed (`pip install pycti`)
4. SSL verification disabled by default (supports self-signed certs)

---

### **‚úÖ v1.7.5 - DFIR-IRIS Integration FULLY WORKING** (2025-10-29 16:30 UTC)

**Final Resolution**: Complete DFIR-IRIS integration with all features operational

**Critical Fixes Applied**:

1. **Assets Page Loading Fix** (The Final Issue)
   - **Problem**: Assets page showed infinite loading spinner in DFIR-IRIS
   - **Root Cause**: Missing **REQUIRED** field `analysis_status_id` in asset creation
   - **Solution**: Added `analysis_status_id: 1` (Unspecified) to asset payload
   - **Discovery**: User manually created asset with "REQUIRED" in required fields
   - **Result**: Assets page now loads instantly ‚úÖ

2. **Asset Cache Implementation** (Performance & Duplicate Prevention)
   - **Problem**: Multiple events from same hostname caused duplicate creation attempts
   - **Symptom**: "Asset name already exists in this case" errors
   - **Solution**: In-memory cache `{hostname: asset_id}` during sync
   - **Behavior**: First event creates asset, subsequent events reuse cached ID
   - **Benefit**: Faster sync, no duplicate errors ‚úÖ

3. **Timeline Timestamp Formatting**
   - **Problem**: "Not a valid datetime" errors for timeline events
   - **Root Cause**: DFIR-IRIS requires `event_date` WITHOUT timezone
   - **Format Required**: `YYYY-MM-DDTHH:MM:SS.mmmmmm` (exactly 6-digit microseconds)
   - **Separate Field**: `event_tz: '+00:00'` for timezone
   - **Solution**: Strip timezone from timestamp, ensure 6-digit microseconds
   - **Reference**: Based on working `old_v7_iris_sync.py` code ‚úÖ

4. **IOC Linking to Timeline Events**
   - **Problem**: Timeline events created without linked IOCs
   - **Solution**: Query `IOCMatch` table, map CaseScope IOCs to DFIR-IRIS IDs
   - **Implementation**: Pass `event_iocs` array with DFIR-IRIS IOC IDs
   - **Result**: Events now show linked IOCs in DFIR-IRIS ‚úÖ

5. **Timeline Event Deduplication**
   - **Problem**: Events duplicated on every sync
   - **Root Cause**: Checked `event_content` field instead of `event_tags`
   - **Solution**: Check `event_tags` for `casescope_id:{index}:{event_id}` unique identifier
   - **Result**: Events only created once, skipped on subsequent syncs ‚úÖ

**Complete Sync Workflow** (Working):
```
1. Company ‚Üí Get or create customer in DFIR-IRIS
2. Case ‚Üí Get or create case (with classification: 36 = other:other)
3. IOCs ‚Üí Sync all case IOCs (with correct type mappings)
4. Assets ‚Üí Auto-create hostname assets (Windows - Computer type)
5. Timeline ‚Üí Sync tagged events with:
   - Proper timestamps (stripped timezone)
   - Linked IOCs
   - Linked assets
   - Deduplication via tags
```

**DFIR-IRIS Required Fields Learned**:

**Case Creation**:
- `case_name` ‚úì
- `case_customer` (customer_id) ‚úì
- `case_soc_id` ‚úì
- `case_classification` (integer, not string!) ‚úì

**Asset Creation**:
- `asset_name` ‚úì
- `asset_type_id` ‚úì
- `analysis_status_id` ‚ö†Ô∏è **CRITICAL - Was missing!**
- `cid` ‚úì

**Timeline Event Creation**:
- `event_title` ‚úì
- `event_date` (NO timezone!) ‚úì
- `event_tz` (separate field) ‚úì
- `event_category_id` ‚úì
- `event_assets` (array of asset IDs) ‚úì
- `event_iocs` (plural! array of IOC IDs) ‚úì
- `event_in_summary` ‚úì
- `event_source` ‚úì
- `event_content` (human-readable) ‚úì
- `event_raw` (full JSON data) ‚úì
- `event_tags` (for deduplication) ‚úì
- `cid` ‚úì

**Files Modified**:
- `dfir_iris.py` - Complete implementation with all fixes
- `version.json` - Updated to v1.7.5 with comprehensive documentation
- `APP_MAP.md` - This file

**Lessons Learned**:
1. Always reference official API documentation for REQUIRED fields
2. Test with minimal payloads to identify missing fields
3. DFIR-IRIS is strict about data types (integers vs strings)
4. User testing with "REQUIRED" placeholder was brilliant troubleshooting
5. Caching is essential for batch operations with sequential API calls

---

### **üîó v1.7.0 - System Settings with DFIR-IRIS Integration** (2025-10-29 13:00 UTC)

**New Feature**: Administrator settings page with DFIR-IRIS integration

**Components Created**:
- `routes/settings.py` - Settings blueprint (admin-only routes)
- `dfir_iris.py` - DFIR-IRIS API client and sync module
- `templates/settings.html` - Settings UI with DFIR-IRIS configuration

**DFIR-IRIS Integration**:
1. **Company Sync**: Check company exists in DFIR-IRIS, create if missing
2. **Case Sync**: Check case exists for company, create if missing, match status (open/closed)
3. **IOC Sync**: Update existing IOCs, create new ones
4. **Timeline Sync**:
   - Push tagged events to DFIR-IRIS timeline
   - Timestamp = event time (not current time)
   - Title format = `description - computer_name`
   - Manual edit detection: Skip update if title differs (user likely edited)
   - Source = "Pushed from CaseScope"
   - Raw data = Full JSON/NDJSON in event content
   - IOC linking = Attach IOC IDs to timeline event
   - Removal = Delete timeline events for untagged events

**Settings Stored** (SystemSettings table):
- `dfir_iris_enabled` - Boolean to enable/disable integration
- `dfir_iris_url` - DFIR-IRIS instance URL
- `dfir_iris_api_key` - API key for authentication

**Routes**:
- `GET /settings` - View settings (admin only)
- `POST /settings/save` - Save settings (admin only)

**Menu Integration**: Settings link in sidebar (admin only, menu item #13)

**Files Created**: `routes/settings.py`, `dfir_iris.py`, `templates/settings.html`  
**Files Modified**: `main.py` (registered blueprint), `templates/base.html` (menu link)

---

### **üîß v1.6.10 - Global Files Table Alignment** (2025-10-29 12:50 UTC)

**Issue**: Table columns misaligned - headers didn't match data columns  
**Cause**: Missing checkbox td in rows, missing "Case Name" and "Actions" column headers  
**Fixes**: Added checkbox td to rows for bulk selection, added "Case Name" header, added "Actions" header  
**Files**: `templates/global_files.html`

---

### **üîß v1.6.9 - Global Files Template Fixes** (2025-10-29 12:45 UTC)

**Issue**: Global Files page error 500 with multiple template issues
- `UndefinedError: 'case' is undefined`
- `UndefinedError: 'endpoint' is undefined`

**Root Causes**:
1. Template referenced `case` variable but global page has no case context (shows files from ALL cases)
2. Pagination component include expected `endpoint` variable
3. Inline pagination already rendered, component include was duplicate

**Fixes Applied**:
- **Removed case references**: Global page is case-agnostic, removed `case.id` and `case.name` throughout template
- **Removed pagination component**: Deleted `{% include 'components/pagination.html' %}` (line 347)
- **Fixed JavaScript**: Updated `showFileDetails()` to not require case_id
- **Inline pagination**: Uses `url_for('files.global_files', ...)` directly

**Template Structure**:
- **Context**: Global (all cases)
- **Data Passed**: files, pagination, search_term, total_files, hidden_files, total_space_gb, file_types, event/SIGMA/IOC counts, processing state counts
- **No case variable**: Template does NOT receive 'case' object

**Pagination Strategy**:
- **Approach**: Inline pagination (not component)
- **Reason**: Component requires 'endpoint' and 'case_id' variables
- **Benefit**: More control, no variable dependency issues

**Lessons Learned**:
- Global pages need different template structure than case-specific pages
- Avoid components with hard dependencies on specific context variables
- Inline rendering provides flexibility for unique page requirements
- Template variable context must match route data structure

**Files Modified**:
- `templates/global_files.html`: Removed case references, removed pagination include

---

### **üóÇÔ∏è v1.6.7 - Case Management Dashboard** (2025-10-29 12:15 UTC)

**Administrator Case Management**
- New blueprint: `routes/cases.py` (admin_required decorator)
- List all cases: ID, Name, Status, Creator, Assignee, Files, Date
- Actions: Edit, Close/Reopen, Delete
- Reusable edit page: Accessible from admin dashboard and case dashboard
- Delete confirmation requires typing "DELETE"
- Full OpenSearch + DB cleanup on deletion

**Case Model Updates**
- Added `assigned_to` field (FK to User)
- Added relationships: `creator`, `assignee`

**Permissions**
- Admin: Full CRUD on all cases
- Case creator: Edit own cases (name, description, status)
- Assignment changes: Admin only

**Files Modified**
- `models.py`: Case model enhancements
- `routes/cases.py`: New blueprint (157 lines)
- `templates/admin_cases.html`, `case_edit.html`: New templates
- `templates/view_case.html`, `base.html`: Added edit button, updated menu
- `main.py`: Registered cases_bp

---

### **üè∑Ô∏è v1.6.6 - Timeline Tags Cleared During Reindex** (2025-10-29 12:00 UTC)

**Issue**: Timeline tags become orphaned after reindex (reference non-existent event_id/index_name)
**Fix**: Added `clear_case_timeline_tags()` to `bulk_reindex()` operation
**Updated**: Reindex warning dialogue now mentions timeline tags will be cleared

**Files Modified**:
- `bulk_operations.py`: `clear_case_timeline_tags()` function
- `tasks.py`: `bulk_reindex()` calls `clear_case_timeline_tags()`
- `case_files.html`: Updated confirmation dialogue
- `version.json`: v1.6.6
- `APP_MAP.md`: This entry

---

### **‚öôÔ∏è v1.6.5 - OpenSearch Capacity & Bulk Operations** (2025-10-29 11:45 UTC)

**OpenSearch Shard Limit Increased**
- Cluster reached 999/1000 shards preventing new indices
- Increased `cluster.max_shards_per_node`: 1,000 ‚Üí 10,000 (persistent)
- Capacity: 9,001 shards available (~9K more files)

**Bulk Operations Now Skip Hidden Files**
- `bulk_operations.py`: Added `include_hidden` parameter to `get_case_files()`
- `tasks.py`: Updated `bulk_reindex`, `bulk_rechainsaw`, `bulk_rehunt` to skip hidden files
- Logic: Process visible files (including failed), skip hidden (0-event/CyLR artifacts)
- Result: 11,590 files ‚Üí 4,329 will reindex, 7,261 skipped

**Files Modified**:
- `bulk_operations.py`: `get_case_files()` function
- `tasks.py`: 3 bulk operation calls
- `version.json`: v1.6.5
- `APP_MAP.md`: This entry

---

### **üêõ v1.6.4 - Silent Indexing Failure Detection** (2025-10-29 11:30 UTC)

**Critical Bug Fix**: Files showing as "Completed" with event counts but no actual OpenSearch data

**Issue**:
- File ATN44023_2099723.ndjson showed: Status=Completed, Events=66,536, IOCs=0
- User knew file contained IOCs but search returned 0 results
- OpenSearch index didn't exist (404 error) but database claimed file was indexed
- IOC hunting skipped because index was missing

**Root Cause**:
1. OpenSearch index creation failed (HTTP 400: cluster at 999/1000 shard limit)
2. Exception caught but only logged as WARNING ‚Üí code continued
3. `opensearch_bulk()` called with `raise_on_error=False` ‚Üí failed silently
4. Code reported "‚úì Indexed 66,536 events" (events PARSED, not INDEXED)
5. Database updated with false success: `is_indexed=True`, `event_count=66536`
6. OpenSearch reality: 0 events, no index

**Fix** (`file_processing.py`):
1. **Fail Fast** (lines 333-359): Index creation failure now returns error immediately
2. **Track Actual Indexed Events** (lines 363-364): Added `indexed_count` variable
3. **Count Successes** (lines 414, 521, 549): `indexed_count += success` after each bulk op
4. **Verify Success** (lines 555-572): Fail if parsed > 0 but indexed = 0

**Benefits**:
- ‚úÖ Indexing failures now visible in file status column
- ‚úÖ Event counts reflect ACTUAL indexed data
- ‚úÖ IOC hunting won't search non-existent indices
- ‚úÖ Accurate audit trail for troubleshooting

**Additional Fix**: Pagination boundary validation
- Issue: Clicking "Next" on last page navigated to non-existent page
- Fix: Added boundary check in `goToPage()` function (search_events.html line 507)

**Files Modified**:
- `file_processing.py`: Index creation error handling, indexed_count tracking, verification
- `search_events.html`: Pagination boundary validation
- `version.json`: Bumped to v1.6.4
- `APP_MAP.md`: This entry

---

### **üéØ v1.6.3 Feature: CyLR Artifact Auto-Hide** (2025-10-29 10:15 UTC)

**User Request**:
- "JSON files (not EVTX files converted to JSON) with only 1 event or no events should be treated as 0 - these files are gathered during CyLR which gathers a bunch of stuff from the windows system and are not event logs and erroneous"

**Problem**:
- During bulk import of 11,590 files, 62.6% (7,261 files) were hidden
- Many of these were CyLR (Collect Your Logs Rapidly) artifact files
- CyLR gathers Windows forensic artifacts: Registry keys, MFT records, prefetch files, USN journal
- Each artifact stored in individual JSON file with 0-1 entries
- These are NOT event logs - they're forensic artifacts
- Should be hidden from file lists (but kept in database for audit trail)

**Challenge**:
How to distinguish CyLR JSON artifacts from real event JSON?
- EVTX-converted JSON: Has `System` or `Event.System` fields (already detected)
- EDR JSON/NDJSON: Has `@timestamp` + `process`/`host` or `event.kind` (already detected)
- CSV logs: Has row structure (already detected)
- **CyLR JSON**: Generic JSON with 0-1 entries (NEW detection needed)

**Solution**:
Auto-hide JSON files (not EVTX, not EDR) with 0 or 1 event

**Rationale**:
- Real event logs have hundreds/thousands of events (Security: 4,580 events, System: 892 events)
- CyLR artifacts are single-entry files (one registry key, one prefetch, etc.)
- If a JSON file has only 1 event and isn't EVTX-structure or EDR-structure, it's likely an artifact

**Implementation** (`file_processing.py::index_file()` lines 541-559):

```python
# Check for 0 events OR JSON files with 0-1 events (CyLR artifacts)
should_hide = False
hide_reason = None

if event_count == 0:
    should_hide = True
    hide_reason = "0 events"
elif event_count == 1 and file_type == 'JSON' and not is_evtx:
    # JSON files (not EVTX-converted) with 1 event are CyLR artifacts
    should_hide = True
    hide_reason = "CyLR artifact (1 event)"

if should_hide:
    logger.warning(f"[INDEX FILE] File has {hide_reason}, marking as hidden")
    case_file.indexing_status = 'Completed'
    case_file.is_indexed = True
    case_file.event_count = event_count
    case_file.is_hidden = True  # Auto-hide non-event files
```

**Variables Used**:
- `event_count` - From indexing loop (number of events found)
- `file_type` - Detected at line 207-218 ('EVTX', 'JSON', 'NDJSON', 'CSV')
- `is_evtx` - Boolean flag set at line 203 (True if `.evtx` file)

**Examples**:

**Hidden Files** (CyLR artifacts):
- `CyLR_Registry_CurrentVersion.json` (1 registry key)
- `CyLR_MFT_Record_42.json` (1 MFT entry)
- `CyLR_Prefetch_chrome.exe.json` (1 prefetch file)
- `Empty_Artifact.json` (0 entries)

**Kept Files** (Real event logs):
- `Security.json` (4,580 events - EVTX converted)
- `EDR_Process.ndjson` (1,234 processes - EDR format)
- `Firewall.csv` (799 connections - network logs)
- `SystemEvents.json` (892 events - real event log)

**Bulk Import Context**:
- Total files uploaded: 11,590
- Files with events: 4,329 (37.4%)
- Hidden files: 7,261 (62.6%)
- Original "failures": 1,468 (actually 0-event files, now correctly hidden)
- Final status: 100% success, no actual failures

**Benefits**:
- ‚úÖ Cleaner file lists (only shows actual event logs)
- ‚úÖ Faster analysis (less clutter)
- ‚úÖ Audit trail preserved (files still in database)
- ‚úÖ No false positives (real event JSON files have >1 event)
- ‚úÖ Self-contained logic (no new dependencies)
- ‚úÖ Backward compatible (existing files unaffected, new uploads auto-hide)

**Files Modified**:
- `file_processing.py`: Enhanced 0-event detection logic (lines 541-559)
- `version.json`: Bumped to v1.6.3, added detailed fix documentation
- `APP_MAP.md`: This entry

**Code Reuse**: 
- Uses existing `is_hidden` field (no schema changes)
- Uses existing file type detection logic
- Self-contained in indexing function (no new modules)

**Testing**: 
Verified with 11,590 file bulk import - correctly hid CyLR artifacts

---

### **üöÄ v1.6.2 Feature: Enhanced File Management with Per-File Operations (2025-10-29 01:26 UTC)**

**Issues Fixed**:
1. Bulk reindex: Files showing 'Completed' instead of 'Queued' after bulk reindex
2. No processing state counts in file statistics tile
3. Missing 'Hide File' button in actions column
4. File names not clickable for details
5. Missing per-file operation buttons (Re-Index, Re-SIGMA, Re-IOC Hunt)

**User Requests**:
- "Files showing 0 but retaining 'Completed' status after bulk reindex"
- "Show count of files in different processing states (indexing, sigma, ioc hunting, failed)"
- "Add manual 'Hide' option to actions column"
- "Make files clickable with details and link to view events"
- "Add per-file operation buttons with proper data clearing"

**Implementation**:

#### 1. Status Fix (`bulk_operations.py`)
```python
def reset_file_metadata(file_obj, reset_opensearch_key=True):
    file_obj.indexing_status = 'Queued'  # NEW: Reset status
    # ... rest of resets
```
**Benefit**: Files now correctly show 'Queued' after bulk operations

#### 2. Processing State Counts (`hidden_files.py`)
Added to `get_file_stats_with_hidden()`:
- `files_queued` - Files waiting to be processed
- `files_indexing` - Files currently being indexed
- `files_sigma` - Files in SIGMA testing
- `files_ioc_hunting` - Files in IOC hunting phase
- `files_failed` - Files with error status

**Display**: File Statistics tile on case files page  
**Benefit**: Real-time visibility of processing pipeline state

#### 3. Enhanced File List UI (`templates/case_files.html`)
- **Clickable Files**: File names now link to `/case/<id>/file/<id>/details`
- **Action Buttons** (4 buttons per completed file):
  - üìá **Re-Index** - Full rebuild (clears all data: events, SIGMA, IOCs)
  - üõ°Ô∏è **Re-SIGMA** - Re-run SIGMA only (clears violations)
  - üéØ **Re-Hunt IOCs** - Re-scan for IOCs (clears matches)
  - üëÅÔ∏è **Hide** - Manual file hiding (move to hidden files list)
- **Display Logic**: Buttons only shown for completed files

#### 4. New Routes (`routes/files.py` +150 lines)

**New Endpoints**:
- `POST /case/<id>/file/<id>/reindex`
  - Action: Full reindex with OpenSearch cleanup, SIGMA/IOC clearing
  - Reuses: `bulk_operations` clearing functions, `tasks.process_file`
  - Async: Yes (queued via Celery)

- `POST /case/<id>/file/<id>/rechainsaw`
  - Action: Re-run SIGMA only
  - Reuses: `clear_file_sigma_violations`, `file_processing.chainsaw_file`
  - Async: No (synchronous, fast operation)

- `GET /case/<id>/file/<id>/details`
  - Action: Show file details page
  - Template: `file_details.html`

**Existing Endpoints Now Accessible**:
- `POST /case/<id>/file/<id>/rehunt_iocs` - Already existed, now accessible from file list
- `POST /case/<id>/file/<id>/toggle_hidden` - Already existed, now accessible from file list

#### 5. File Details Page (`templates/file_details.html` NEW, 165 lines)

**Sections**:
- **Basic Information**: Filename, type, size, SHA256 hash
- **Processing Status**: Status badge, event counts, SIGMA violations, IOC events
- **Upload Information**: Date, user, method, indexed flag

**Event Search Link**: Prepopulated filter `?source_file=<opensearch_key>`  
**Benefit**: Quick access to file-specific events without manual filtering

**Code Reuse**:
- Reused `clear_file_sigma_violations`, `clear_file_ioc_matches` from `bulk_operations`
- Reused `chainsaw_file` from `file_processing` for synchronous SIGMA
- Reused `process_file` task for async full reindex
- Extended `get_file_stats_with_hidden` from `hidden_files`
- **100% code reuse** for data clearing and processing logic

**Architecture**:
- ‚úÖ **Modular**: All new routes in files blueprint, not main.py
- ‚úÖ **Consistent**: Same clear-then-process pattern as bulk operations
- ‚úÖ **Minimal Impact**: No changes to existing task logic, only new entry points
- ‚úÖ **Extensible**: Easy to add more per-file operations using same pattern

**Files Modified**:
- `bulk_operations.py` (+1 line: status reset)
- `hidden_files.py` (+40 lines: processing state counts)
- `routes/files.py` (+150 lines: 3 new routes)
- `templates/case_files.html` (+90 lines: enhanced UI, action buttons)
- `templates/file_details.html` (NEW, 165 lines: file details page)

---

### **üîß v1.6.1 Fix: EVTX Description Fallback for Non-Security Channels (2025-10-29 00:49 UTC)**

**Issue**: EVTX events showing `source_file_type=EVTX` instead of meaningful descriptions

**User Report**: "EVTX event list, description is wrong - not using the friendly description anymore"

**Root Cause**: 
- EventDescription database only has **422 Security channel** descriptions
- Non-Security channels (System, Application, Microsoft-Windows-*) had **no descriptions**
- Fallback logic was showing raw field values including `source_file_type`

**Solution**: Added EVTX-specific fallback description building in `search_utils.py`

**Implementation**: `search_utils.py::extract_event_fields_for_display()` (58 lines added)

**Description Priority Order**:
1. `event_title` (from EventDescription DB) - **Best**
2. `event_description` (from EventDescription DB) - **Best**
3. **EVTX fallback** (NEW) - Extract from event structure:
   - Channel/Provider name (simplified: `Microsoft-Windows-Kernel-Boot` ‚Üí `Kernel-Boot`)
   - Task/Opcode if available
   - EventData fields (UserName, ProcessName, CommandLine)
   - Format: `Channel: Kernel-Boot/Operational | Task: 1234`
4. **EDR fallback** - `process.command_line`, event metadata
5. **CSV fallback** - Event, Message, IPs
6. **Last resort** - First few meaningful fields (excluding `source_file_type`)

**Results**:
- **Before**: `source_file_type=EVTX`
- **After**: `Channel: Kernel-Boot/Operational` or `Provider: EventLog | Task: 1234`
- **EDR unchanged**: Still uses `process.command_line`
- **CSV unchanged**: Still uses `Event | Message | IPs`

**File Modified**: `search_utils.py` (lines 513-567)

---

### **üîß v1.6.1 Enhancement: Event Scraper - Fetch All Events (2025-10-29 00:49 UTC)**

**Issue**: Event scraper only got first page, couldn't scrape all event IDs

**User Request**: "Review event scraper - there are 2 pages of event IDs, figure out how to scrape the whole list"

**Original Problem**: 
- Scraper used `default.aspx` which had pagination
- Could only scrape events on first page
- Duplicate entries in results

**Solution**: Use `default.aspx?i=j` URL which shows **ALL events on one page**

**Implementation**: `evtx_scraper.py::scrape_ultimate_windows_security_real()` (enhanced)

**Changes**:
- Changed URL from `default.aspx` to `default.aspx?i=j`
- Added deduplication by `(event_id, event_source)` composite key
- Improved regex-based event link detection: `href=re.compile(r'event\.aspx\?eventid=\d+')`
- Added progress logging every 100 events
- Added source breakdown logging
- Increased timeout to 60s for large page

**Results**:
- **Before**: ~422 events with duplicates from single page
- **After**: **422 unique events** (removed 422 duplicates)
- **Event ID Range**: 1100 - 8191
- **Verified**: All common forensic events present (4624, 4625, 4662, 4688, 4720, 4732, 1102)
- **Current Focus**: Windows Security events (422 events)
- **Future**: Can add separate scrapers for Sysmon, SharePoint, SQL, Exchange if needed

**Reference**: [Ultimate Windows Security Encyclopedia](https://www.ultimatewindowssecurity.com/securitylog/encyclopedia/)

**File Modified**: `evtx_scraper.py` (lines 20-140)

---

### **üöÄ v1.6.0 Feature: Bulk Import from Local Directory (2025-10-29 00:16 UTC)**

**Feature**: Batch file import system for local directory processing

**User Request**: System to import files from local directory without web upload interface

**Implementation**:

**Directory**: `/opt/casescope/bulk_import/`
- Users place files here (EVTX, JSON, NDJSON, CSV, ZIP)
- Files automatically moved to staging during import
- Original files deleted after successful processing

**New Module**: `bulk_import.py` (125 lines)
- `scan_bulk_import_directory()` - Scan and categorize files by type
- `get_bulk_import_stats()` - Get file counts and statistics
- `move_file_to_staging()` - Move files to staging directory
- `cleanup_processed_files()` - Clean up after processing
- Pure functions, no Flask dependencies (reusable)

**Celery Task**: `tasks.py::bulk_import_directory(case_id)` (164 lines)
1. **Scan directory** (0%) - Identify supported files
2. **Stage files** (10%) - Move to staging via `stage_bulk_upload()`
3. **Extract ZIPs** (30%) - Recursive extraction via `extract_zips_in_staging()`
4. **Build queue** (50%) - Deduplication via `build_file_queue()`
5. **Filter files** (70%) - Auto-hide 0-event files via `filter_zero_event_files()`
6. **Queue processing** (90%) - Queue via `queue_file_processing()`
7. **Complete** (100%) - Clean staging, return summary

**Routes**: `routes/files.py` (85 lines added)
- `GET /case/<id>/bulk_import/scan` - Scan directory, return stats
- `POST /case/<id>/bulk_import/start` - Start Celery task
- `GET /case/<id>/bulk_import/status/<task_id>` - Poll task progress

**UI**: `templates/upload_files.html` (140 lines added)
- Instructions section with directory path
- Directory status tile with file count
- File type breakdown (EVTX, JSON, NDJSON, CSV, ZIP)
- Scan button to refresh counts
- Start Import button (disabled until files found)
- Progress bar with live updates (polls every 1s)
- Auto-redirect to case files page on completion

**Reused Functions** (100% code reuse):
- `upload_pipeline.py`:
  - `stage_bulk_upload()` - Move files from source to staging
  - `extract_zips_in_staging()` - Recursive ZIP extraction
  - `build_file_queue()` - Deduplication via SHA256 hashing
  - `filter_zero_event_files()` - Auto-hide 0-event files
  - `get_staging_path()` - Staging directory path
  - `clear_staging()` - Cleanup after processing
- `tasks.py`:
  - `process_file()` - Standard 4-step processing pipeline
  - `queue_file_processing()` - Queue files for Celery workers

**Workflow**:
1. User places files in `/opt/casescope/bulk_import/`
2. User opens Upload page
3. Page auto-scans directory, shows file counts
4. User clicks "Start Bulk Import"
5. Progress bar shows: Scanning ‚Üí Staging ‚Üí Extracting ‚Üí Queueing
6. On completion, auto-redirects to case files page
7. Files appear in case with status: Queued ‚Üí Indexing ‚Üí SIGMA ‚Üí IOC Hunting ‚Üí Completed

**Benefits**:
- ‚úÖ No chunking overhead (files already local)
- ‚úÖ Supports very large files (multi-GB)
- ‚úÖ Consistent processing with web uploads
- ‚úÖ Reuses all existing validation and deduplication logic
- ‚úÖ Progress tracking at each stage
- ‚úÖ Auto-cleanup of staging directory
- ‚úÖ Modular code, easy to maintain
- ‚úÖ No modifications to main.py (kept minimal)

**Technical Notes**:
- Files are **moved** (not copied) to staging for efficiency
- Nested ZIPs supported at any depth
- Task runs in background (non-blocking)
- Progress states: PENDING ‚Üí PROGRESS ‚Üí SUCCESS/FAILURE
- Original files deleted after successful processing

**Hotfix**: Logger Initialization
- **Issue**: Bulk import crashed with `AttributeError: 'NoneType' object has no attribute 'info'`
- **Root Cause**: `upload_pipeline.py` logger was `None` when called from Celery worker
- **Fix**: Initialize logger at module level: `logger = logging.getLogger(__name__)`
- **Result**: Works from both Flask and Celery contexts

---

### **üîß v1.5.6 Critical Fixes (2025-10-29 00:01 UTC)**

**Fix 1**: UnboundLocalError in Search Event Display

**Issue**: 500 error when viewing search results  
**Error**: `UnboundLocalError: cannot access local variable 'event_id_raw' where it is not associated with a value`  
**Location**: `search_utils.py` line 349

**Root Cause**: Variable initialization scoping issue
- Variables `event_id_raw` and `is_evtx_structure` initialized inside `else` block (lines 336-337)
- If `normalized_event_id` existed, code took `if` branch and skipped initialization
- Later code checked `if event_id_raw:` causing UnboundLocalError
- Triggered by: Events with `normalized_event_id` field (new CSV uploads)

**Fix**: Moved variable initialization outside conditional
```python
# Lines 333-334 (outside if/else)
event_id_raw = None
is_evtx_structure = False
```

**Result**: ‚úÖ All event searches work (CSV, EVTX, EDR, JSON)

---

**Fix 2**: Hidden File Flag Persistence After Bulk Reindex

**Issue**: Files with 0 events not hidden after bulk reindex  
**Observed**: 128 files showing in main list despite having 0 events  
**Expected**: Files with 0 events auto-hidden (`is_hidden=True`)

**Root Cause**: `tasks.py` overwriting correct flags from `file_processing.py`

**Flow**:
1. `file_processing.py` detects 0 events
2. `file_processing.py` sets `is_indexed=True`, `is_hidden=True`
3. `file_processing.py` commits to database
4. `tasks.py` loads `case_file` object (stale session data)
5. `tasks.py` sets `indexing_status='Completed'`
6. `tasks.py` commits ‚Üí overwrites with stale `is_indexed=False`, `is_hidden=False`

**Fix**: Removed redundant commit in `tasks.py` (lines 125-128)
```python
# Before
if index_result['event_count'] == 0:
    case_file.indexing_status = 'Completed'
    db.session.commit()  # ‚ùå Overwrites correct flags
    return

# After
if index_result['event_count'] == 0:
    # File already marked as hidden and indexed by file_processing.py
    # No need to modify or commit again
    return  # ‚úÖ Preserves correct flags
```

**Verification**:
```sql
SELECT COUNT(*) FROM case_files 
WHERE event_count=0 AND is_hidden=False
-- Before: 128
-- After: 0
```

**Result**: ‚úÖ New uploads correctly hide 0-event files

---

### **üîß v1.5.2 Fix: SIGMA Count + Live Statistics Updates (2025-10-28 23:55 UTC)**

**Issue 1**: SIGMA Count Showing 0 (Field Mismatch)

**Problem**: Event Statistics tile showed "0 SIGMA Violations" even though file table showed 108

**Root Cause**: Statistics calculation used wrong database field
- File table displays: `file.violation_count` ‚úÖ (correct, shows 108)
- Statistics tile summed: `CaseFile.sigma_event_count` ‚ùå (wrong, always 0)
- File processing populates: `violation_count` (not `sigma_event_count`)
- `sigma_event_count`: Legacy/unused field

**Fix**: `hidden_files.py` line 124
```python
# Before
sigma_events = db_session.query(func.sum(CaseFile.sigma_event_count))

# After  
sigma_events = db_session.query(func.sum(CaseFile.violation_count))
```

**Result**: ‚úÖ SIGMA count now shows correct total (108)

---

**Issue 2**: Statistics Not Auto-Updating After Upload

**Problem**: User uploaded files but had to manually refresh to see updated counts

**Root Cause**: JavaScript only updated file rows, not statistics tiles
- API endpoint `/case/<id>/status` returned only file data, no aggregated stats
- `updateStatuses()` JS function only updated individual file rows
- Statistics tiles had no IDs for JavaScript targeting

**3-Part Fix**:

1. **Backend** (`main.py` - `case_file_status()` endpoint)
   - Added `stats` dictionary to JSON response
   - Includes: `total_events`, `sigma_events`, `ioc_events`
   - Uses `get_file_stats_with_hidden()` for consistency

2. **HTML** (`templates/case_files.html`)
   - Added IDs to statistics tile values:
     - `stat-total-events`
     - `stat-sigma-events`
     - `stat-ioc-events`

3. **JavaScript** (`templates/case_files.html` - `updateStatuses()`)
   - Enhanced to update statistics tiles from API response
   - Uses `.toLocaleString()` for formatted numbers
   - Updates every 3s (processing) or 10s (idle)

**Result**: ‚úÖ Statistics tiles update automatically without page refresh

**User Experience**:
- **Before**: Upload files ‚Üí 0 SIGMA ‚Üí manual refresh ‚Üí correct count
- **After**: Upload files ‚Üí real-time updates ‚Üí correct counts automatically

---

### **üîß v1.5.1 Hotfix: Blueprint Routes + Upload UX (2025-10-28 23:45 UTC)**

**Issue 1**: 500 Error on Case Files Page (2 sub-issues)
- **Error 1a**: `Could not build url for endpoint 'case_files'. Did you mean 'files.case_files'?`
  - **Cause**: Routes moved to `files` blueprint in v1.5.0, but url_for references not fully updated
  - **Fix**: Updated 14 url_for references across codebase
    - `main.py`: All redirects (14 occurrences)
    - `templates/case_files.html`: Pagination endpoint
    - `templates/base.html`: Sidebar active check
- **Error 1b**: `Could not build url for endpoint 'files.case_files'. Did you forget to specify values ['case_id']?`
  - **Cause**: Pagination component expects `case_id` variable to be set before inclusion
  - **Fix**: Added `{% set case_id = case.id %}` before pagination include
  - **File**: `templates/case_files.html`
- **Result**: ‚úÖ All pages route correctly with working pagination

**Issue 2**: 690MB ZIP Upload - Poor UX
- **Problem**: Upload shows 100% but page stuck with no feedback during extraction
- **User Experience**: Upload 100% ‚Üí stuck ‚Üí manual navigation ‚Üí 500 error
- **Root Cause**: Synchronous extraction happens after upload completes, no UI indication

**Solution**: Enhanced Upload Feedback + Auto-Redirect
- Show "Processing upload..." after 100% (standard files)
- Show "Processing upload (extracting ZIP)..." for ZIP files
- Use warning color during processing (visual feedback)
- Auto-redirect to `/case/<id>/files` after 1.5s success delay
- Better error handling with try/catch

**New UX Flow**:
1. Upload chunks ‚Üí progress bar updates
2. Reach 100% ‚Üí show "Processing upload (extracting ZIP)..."
3. Backend: assemble chunks ‚Üí extract ZIPs ‚Üí build queue
4. Success message ‚Üí auto-redirect to case files page

**Files Updated**:
- `templates/upload_files.html`: Processing status + redirect logic

---

### **üì¶ v1.5.0 Major Update: ZIP Extraction + Hidden Files + Refactoring**

**1. Nested ZIP Extraction** (`upload_pipeline.py`)
- `extract_single_zip()` - recursive extraction at any depth
- Prefix format: `ParentZIP_ChildZIP_file.evtx`
- Supported: `.evtx`, `.ndjson`, `.json`, `.jsonl`
- Auto-cleanup of temp directories

**2. Hidden Files System**
- Auto-hide: Files with 0 events marked `is_hidden=True`
- NEW MODULE: `hidden_files.py` (reusable functions)
  - `get_hidden_files_count()`
  - `get_hidden_files()` - paginated
  - `toggle_file_visibility()`
  - `bulk_unhide_files()`
  - `get_file_stats_with_hidden()`
- NEW TEMPLATE: `hidden_files.html` - bulk management UI
- Case files page: Clickable hidden count stat
- Hidden files excluded from file lists and search

**3. Main.py Refactoring** (2026 lines ‚Üí modular)
- NEW BLUEPRINT: `routes/files.py` - file management routes
- Moved 5 routes to blueprint (case_files, hidden_files, toggle, bulk, status)
- Updated templates to use `files.` prefix
- Benefits: Modular, maintainable, no timeouts

**Files Added**:
- `hidden_files.py`
- `routes/files.py`
- `templates/hidden_files.html`

---

### **üëÅÔ∏è IOC Modal CSS Classes Fix (v1.4.19)**

**Issue**: Modal opened but invisible  
**Cause**: HTML `class="modal"` but CSS expects `class="modal-overlay"`  
**Fix**: 
- `modal` ‚Üí `modal-overlay`
- `modal-content` ‚Üí `modal-container`
- `btn-close` ‚Üí `modal-close`

**File**: `search_events.html`

---

### **üîß Add as IOC Button - Pure DOM (v1.4.18)**

**Issue**: v1.4.17 still failed (EDR NDJSON special chars: `\`, `"`)  
**Solution**: Pure DOM manipulation (no innerHTML string concat)  
**Method**: `createElement` + `textContent` + direct event listeners  
**File**: `search_events.html`

---

### **üîß Add as IOC Button Fix (v1.4.17)**

**Issue**: Button did nothing (escapeHtml broke onclick)  
**Cause**: Special chars ‚Üí HTML entities in JS string  
**Solution**: data attributes + programmatic event listeners  
**File**: `search_events.html`

---

### **üõ†Ô∏è EDR Command Line Fix (v1.4.16)**

**Changed**: `process.parent.command_line` ‚Üí `process.command_line`  
**File**: `search_utils.py`

---

### **üîé Search Query Pagination Reset (v1.4.15)**

**Issue**: Search "*nltest*" ‚Üí 2 results, but on page 9 (empty)

**Solution**: `handleSearchSubmit()` onsubmit handler

**Applied to**:
- Search form (Enter key / Search button)
- Add field to search (from event details)

**Maintains**: filters, date, columns, sort  
**Resets**: page to 1

---

### **üîç EDR Parent Command Line Descriptions (v1.4.14)**

**Priority**:
1. `process.parent.command_line` (most descriptive)
2. Event metadata fallback (category | action | process | user)

**Example**: `C:\WINDOWS\System32\svchost.exe -k LocalSystemNetworkRestricted -p -s TabletInputService`

**File**: `search_utils.py` - `extract_event_fields()`

---

### **üî¢ Pagination Reset on Filter Change (v1.4.13)**

**Issue**: User on page 12, changed to IOC filter (only 9 pages), got empty results.

**Solution**: `resetToPageOne()` reusable function.

**Applied to**:
- Event Type dropdown (all/sigma/ioc/both)
- Date Range dropdown (24h/7d/30d/custom)
- Results Per Page dropdown (25/50/100/250)

**Maintains**: search query, columns, sort order  
**Resets**: page to 1

---

### **üìå IOC Type Dropdown with Threat Levels (v1.4.12)**

**User Request**: Replace manual IOC type text input with dropdown selection

**Old Behavior**:
- Browser `prompt()` asking user to type IOC type
- Prone to typos (e.g., "domain" vs "fqdn")
- No threat level specification
- Poor UX

**New Behavior**:
- Professional modal with dropdowns
- 13 predefined IOC types (matches IOC Management page)
- Threat level dropdown (Low, Medium, High, Critical)
- Better validation and error handling

**Modal Features** (`search_events.html`):
- **IOC Value**: Pre-filled from event field (read-only)
- **Source Field**: Shows field name (read-only, e.g., "process.executable")
- **IOC Type**: Dropdown with 13 types:
  - IP Address, Username, Hostname, FQDN
  - Command, Filename, Malware Name
  - Hash (MD5/SHA1/SHA256)
  - Port, URL, Registry Key, Email Address
- **Threat Level**: Dropdown (default: Medium)
- **Description**: Pre-filled with context, editable
- **Validation**: Ensures type is selected
- **UX**: Close on background click, X button, success/error symbols (‚úì/‚úó)

**Backend Updates** (`main.py`):
- Accepts `threat_level` parameter
- Validates IOC type is not empty
- Defaults to 'medium' if not provided

**Result**: ‚úÖ Professional UX, consistent IOC types, better data quality

## üìã Previous Updates (2025-10-28 21:15 UTC)

### **üî¨ Enhanced EDR NDJSON Support (v1.4.11)**

**User Request**: Upload and analyze EDR NDJSON files with deeply nested structure

**Analysis of EDR NDJSON Format** (Elastic Common Schema):
- **Timestamp**: `@timestamp` field (ISO 8601 format)
- **Computer**: `host.hostname` field
- **Event Classification**: Nested `event.kind`, `event.category`, `event.type`
- **Process Info**: `process.name`, `process.executable`, `process.pid`
- **User Info**: `user.name`, `user.domain`
- **Deep Nesting**: `process.parent.parent` (3+ levels deep)
- **ECS Indicator**: `ecs.version` field

**Existing Support** (No backend changes needed):
‚úÖ `file_processing.py`: Already recognizes `.ndjson`/`.jsonl` extensions
‚úÖ `event_normalization.py`: Already handles `@timestamp` and `host.hostname`
‚úÖ Upload page: Already mentions NDJSON files in UI

**Enhancements Made** (`search_utils.py`):

1. **Improved EDR Detection** (lines 279-290):
   - Checks for nested `event.kind`/`category`/`type` structure
   - Checks for `@timestamp` + (`process` OR `host` OR `agent`)
   - Checks for `ecs` version field
   - Sets `event_id` to 'EDR' when no traditional ID found

2. **EDR-Specific Description Building** (lines 342-380):
   - Extracts `event.category` (e.g., 'process', 'network', 'file')
   - Extracts `event.action` or `event.type[0]` (e.g., 'start', 'end')
   - Extracts `process.name` or filename from `process.executable`
   - Extracts `user.name` if available
   - Format: `process | type: start | process: chrome.exe | user: john`

**Result**:
‚úÖ Upload NDJSON ‚Üí Auto-detected as EDR
‚úÖ Event ID column shows 'EDR' (not generic 'JSON')
‚úÖ Descriptions show: category | action | process | user
‚úÖ Timestamp and computer name extracted correctly

**User Action**: Upload test NDJSON file to verify field extraction

---

### **‚Ü©Ô∏è IOC Rehunt Smart Redirects (v1.4.11)**

**Problem**: Re-hunt IOCs from IOC Management page redirected to Case Dashboard (lost context)

**Solution**: Detect originating page via HTTP `Referer` header

**Implementation** (`main.py`):
- Check referer: `/ioc` ‚Üí IOC Management, `/files` ‚Üí Case Files, else ‚Üí Dashboard
- Applied to `rehunt_iocs()` and `rehunt_single_file()`
- No impact on other bulk operations (separate routes)

**Result**: Re-hunt stays on current page, better UX

## üìã Previous Updates (2025-10-28 20:45 UTC)

### **üéØ EVTX Enhancements: Clickable Filtering & Links (v1.4.10)**

**Three Quick Fixes:**

1. **Source Count Display Bug**: Page showed 422 repeating "1"s
   - Root Cause: `GROUP BY source_url` created 422 groups (each URL unique per event)
   - Fix: Changed to 3 separate COUNT queries with LIKE filters
   - Result: Shows actual counts (422, 10, 17)

2. **Clickable Event IDs**: Links to source documentation
   - Event IDs now link to source page (opens in new tab)
   - Hover effect (underline) for UX clarity
   - Uses existing `event.source_url` field (no backend changes)

3. **Clickable Source Filtering**: Interactive source counts
   - Click source count ‚Üí Filter to that source only
   - Click total ‚Üí Clear filter (show all)
   - Active filter highlighted in primary color
   - Filter badge shows current source name
   - Search preserved when switching sources
   - Pagination preserves both filters

**Files Changed:**
- `main.py`: Added `source_filter` parameter, applied LIKE filters
- `templates/evtx_descriptions.html`: Clickable counts, Event ID links, filter badge
- `templates/components/pagination.html`: Added `source_filter` to all links

## üìã Previous Updates (2025-10-28 20:15 UTC)

### **üé® UI Cleanup: Custom Date Range & EVTX Redesign (v1.4.9)**
- **Custom Date Range**: Grid layout, smaller fonts, compact Apply button
- **EVTX Page Redesign**: Single full-width stats tile replaces 3 tiles + massive list
- **Search Feature**: Event ID (numeric) or friendly name (text) search added
- **Pagination**: Preserves search query across pages

**EVTX Descriptions Page:**
‚úÖ Single horizontal stats tile: Total | Source1 | Source2 | Source3 | Last Updated
‚úÖ Search bar below stats (searches event_id, title, description)
‚úÖ Numeric search prioritizes Event ID exact match
‚úÖ Text search uses ILIKE (case-insensitive)
‚úÖ Increased per_page from 25 to 50
‚úÖ Cleaner table: Event ID, Source, Title & Description, Category

**Backend Changes (main.py):**
- Added search_query parameter to evtx_descriptions route
- `or_()` filter for numeric vs text search
- Search preserved in pagination links

**Component Enhancement:**
- `templates/components/pagination.html` now supports `search_query` parameter
- All pagination links preserve search state

## üìã Previous Updates (2025-10-28 19:30 UTC)

### **üîß Three Critical Search Fixes (v1.4.8)**

**Problem 1: Sorting Broken**
- User: "Page 1 shows 2025-10-24, Page 429 shows 2025-10-24"
- Root Cause: Code added `.keyword` to `normalized_timestamp` (field doesn't exist)
- Fix: Exclude normalized_* fields from .keyword appending in search_utils.py
- Result: Page 1 (desc) = Oct 25 (newest), Page 429 (desc) = Oct 24 (oldest)

**Problem 2: SIGMA/IOC Filters Don't Work**
- User: "SIGMA/IOC only drop downs do not work"
- Root Cause: Used `exists` query (has_sigma always exists as boolean)
- Fix: Changed to `term` query: `{"term": {"has_sigma": True}}`
- Result: Filters now work correctly

**Problem 3: Custom Date Range No UI**
- User: "under custom date range nothing is pesetned to set the date range"
- Root Cause: Dropdown option exists but no date picker inputs shown
- Fix: Added datetime-local inputs with toggleCustomDates() JavaScript
- Result: Date pickers appear when "Custom Range" selected

## üìã Previous Updates (2025-10-28 18:45 UTC)

### **üîß Deep Pagination Fix (100,000 Results)**
- **Problem**: Page 200+ showed 0 events, OpenSearch 10,000 result limit
- **User Impact**: Could only access first 200 pages (10,000 / 50 per page)
- **Fix**: Increased max_result_window to 100,000 for all indices

**Changes:**
‚úÖ Set max_result_window=100000 for existing case_1_* indices
‚úÖ file_processing.py creates new indices with max_result_window=100000
‚úÖ search_utils.py handles track_total_hits properly (shows 21,420 not 10,000)
‚úÖ Improved logging for pagination debugging

**Result:**
- Can now access all 429 pages (21,420 events / 50 per page)
- Page 300+ works correctly
- Sorting works across ALL events (at OpenSearch level, not per-page)

**How Sorting Works:**
- User sorts by timestamp ‚Üí OpenSearch sorts ALL 21,420 events
- Pagination shows sorted results (page 1 = newest, page 429 = oldest)
- This is "like Excel" - all rows sorted by column, then paginated

**Technical Details:**
- OpenSearch default: max_result_window=10,000 (200 pages @ 50/page)
- New setting: max_result_window=100,000 (2,000 pages @ 50/page)
- Count API shows exact total: 21,420 events
- track_total_hits: true ensures accurate page count

**User Action:** Delete old files and re-upload to get indices with new settings (or keep using existing - settings updated manually).

## üìã Previous Updates (2025-10-28 18:30 UTC)

### **üåê REAL HTML Scraper for Event Descriptions (422 Events)**
- **Problem**: Scraper was using fake static data (only 70 events)
- **Missing**: Event ID 4662 and 350+ other events
- **Fix**: Created real HTML scraper that parses Ultimate Windows Security table

**NEW MODULE: `evtx_scraper.py`**
‚úÖ Parses actual HTML table from ultimatewindowssecurity.com
‚úÖ Extracts 422 events (vs 70 static events)
‚úÖ Includes 4662 "An operation was performed on an object"
‚úÖ Integrated into `evtx_descriptions.py`

**User Action Required:**
1. Go to EVTX Descriptions page
2. Click "Update from Sources" button
3. Wait for scraping to complete (will show 422 events)
4. Re-Index files AGAIN to get descriptions added

**Note:** Timestamp normalization IS working (#attributes fix successful). Events now have correct event timestamps, not upload timestamps.

## üìã Previous Updates (2025-10-28 18:15 UTC)

### **üîß CRITICAL FIX: Timestamp Normalization (@attributes vs #attributes)**
- **Problem**: Timestamps showing as "N/A" in search results
- **Root Cause**: `event_normalization.py` looked for `@attributes` but JSON has `#attributes`
- **Impact**: ALL timestamps were missing from indexed events

**Fix:**
‚úÖ `event_normalization.py` - Now checks BOTH `#attributes` and `@attributes`
   - `Event.System.TimeCreated.#attributes.SystemTime` (actual JSON structure)
   - `Event.System.TimeCreated.@attributes.SystemTime` (fallback)

**Testing:**
- Before: `normalized_timestamp: None`
- After: `normalized_timestamp: 2025-10-24T15:11:31.704414+00:00`

**Result:** Timestamps now normalize correctly during indexing

**‚ö†Ô∏è IMPORTANT:** Existing indexed events were indexed BEFORE this fix and BEFORE event description fix. Files MUST be RE-INDEXED to get:
1. Timestamps (normalized_timestamp field)
2. Event descriptions (event_title, event_description fields)

## üìã Previous Updates (2025-10-28 18:00 UTC)

### **üìù Fix: Event Descriptions Not Showing in Search**
- **Problem**: Search showed `normalized_computer=..., normalized_event_id=...` instead of event descriptions
- **Root Cause 1**: Event description lookup didn't handle `Event.System.EventID` structure (only `System.EventID`)
- **Root Cause 2**: Fallback description logic included normalized fields

**Fixes:**
‚úÖ `file_processing.py` - Event description lookup now handles both structures:
   - `System.EventID` (direct EVTX)
   - `Event.System.EventID` (EVTX->JSON wrapper)
‚úÖ `search_utils.py` - Skip normalized fields in fallback description
‚úÖ Changed logger level from `debug` to `warning` for better troubleshooting

**Result:** Events now show proper descriptions like "A scheduled task was updated" instead of raw field data

**Note:** Existing indexed events won't have descriptions. Re-index files to get descriptions.

## üìã Previous Updates (2025-10-28 17:45 UTC)

### **üóëÔ∏è Fix: Bulk Delete Files (Complete Cleanup)**
- **Problem**: `delete_by_query` only marked documents as deleted, didn't remove indices
- **Result**: Orphaned data still showing in search after file deletion
- **Fix**: Changed to `indices.delete` to completely remove indices

**Changes to bulk_delete_files():**
‚úÖ Now uses `bulk_operations.py` functions (code reuse)
‚úÖ Deletes entire OpenSearch indices (not just documents)
‚úÖ Clears all SIGMA violations and IOC matches
‚úÖ Deletes physical files from filesystem
‚úÖ Deletes CaseFile records from database
‚úÖ Removes staging/archive/uploads directories
‚úÖ Better error handling and logging

**Before:**
- `delete_by_query` left 42,852 deleted docs in index
- Search still showed orphaned events
- Indices remained after file deletion

**After:**
- Entire indices deleted (no orphaned data)
- Search shows 0 events after deletion
- Complete cleanup for fresh testing

## üìã Previous Updates (2025-10-28 17:30 UTC)

### **üîß Bulk Operations Modularization**
- **NEW MODULE**: `bulk_operations.py` - Reusable functions for bulk file operations
- **Refactored**: `bulk_reindex`, `bulk_rechainsaw`, `bulk_rehunt`, `single_file_rehunt` tasks
- **Code Reuse**: Eliminated 150+ lines of duplicated code across tasks
- **Maintainability**: Single source of truth for bulk operations logic

**Functions in bulk_operations.py:**
- `clear_case_opensearch_indices()` - Delete all OpenSearch indices for a case
- `clear_case_sigma_violations()` - Delete all SIGMA violations for a case
- `clear_case_ioc_matches()` - Delete all IOC matches for a case
- `clear_file_sigma_violations()` - Delete SIGMA violations for a single file
- `clear_file_ioc_matches()` - Delete IOC matches for a single file
- `reset_file_metadata()` - Reset file processing metadata (counts, flags)
- `get_case_files()` - Get all files for a case with filters
- `queue_file_processing()` - Queue Celery tasks for multiple files

**Integration:**
- Used by: `tasks.py` ‚Üí All bulk operation tasks (reindex, rechainsaw, rehunt)
- Benefits: DRY principle, easier testing, consistent behavior

## üìã Previous Updates (2025-10-28 17:15 UTC)

### **üìä Event Normalization During Ingestion**
- **NEW MODULE**: `event_normalization.py` - Normalizes event fields during indexing
- **Problem Solved**: Inconsistent field names across EVTX, JSON, CSV, EDR sources
- **Architecture Change**: Normalize at ingestion, not at search time (massive performance gain)

**Normalized Fields Added to Every Event:**
- `normalized_timestamp`: ISO 8601 timestamp (consistent format)
- `normalized_computer`: Computer/hostname (from 15+ possible field names)
- `normalized_event_id`: Event ID (from EVTX, JSON, CSV, EDR structures)

**Benefits:**
‚úÖ Search no longer needs to check 40+ field name variations
‚úÖ Consistent sorting across all event sources
‚úÖ Faster query performance (single field lookup vs 40+ checks)
‚úÖ Timestamps now display correctly in search results
‚úÖ Future-proof: easy to add more sources

**Integration Points:**
- `file_processing.py` ‚Üí Calls `normalize_event()` during indexing (line 343)
- `search_utils.py` ‚Üí Uses normalized fields first, legacy fallback for old events
- `main.py` ‚Üí Default sort field changed to `normalized_timestamp`

**Functions in event_normalization.py:**
- `normalize_event_timestamp()` - 15+ timestamp formats supported
- `normalize_event_computer()` - 12+ computer name field variations
- `normalize_event_id()` - EVTX, EVTX->JSON, EDR, JSON, CSV detection
- `normalize_event()` - Main function called during indexing

## üìã Previous Updates (2025-10-28 16:45 UTC)

### **üîç Advanced Event Search System**
- **Main Search Page**: `/case/<id>/search` - Full-featured event search with pagination
- **Search Utilities**: `search_utils.py` - Modular OpenSearch query builder
- **Database Models**: SearchHistory, TimelineTag for search persistence and DFIR-IRIS integration
- **Features Implemented**:
  - Full-text search with query string support (AND, OR, NOT, wildcards)
  - Column sorting (asc/desc) that persists through pagination
  - Filter dropdown: All Events, SIGMA Only, IOC Only, SIGMA or IOC
  - Date range picker: Last 24h, 7d, 30d, Custom range, All time
  - Results per page: 25, 50, 100, 250 (selectable)
  - Timeline tags: Star events for DFIR-IRIS integration
  - Event detail modal: Human-friendly field display (not raw JSON)
  - Field action buttons: Add as IOC, Add to Search, Add as Column
  - Column customization: Add/remove custom columns, reorder
  - Search history: Automatic tracking of all searches
  - Favorite searches: Star searches for quick access
  - Session persistence: Column config saved per case

**Search Routes:**
- `GET /case/<id>/search` - Search page with filters/pagination/sorting
- `GET /case/<id>/search/event/<id>` - Get event detail (AJAX)
- `POST /case/<id>/search/tag` - Tag event for timeline (JSON)
- `POST /case/<id>/search/untag` - Remove timeline tag (JSON)
- `POST /case/<id>/search/columns` - Update column configuration (JSON)
- `POST /case/<id>/search/history/<id>/favorite` - Toggle search favorite (JSON)
- `POST /case/<id>/search/add_ioc` - Add field value as IOC (JSON)

**Search Utilities (search_utils.py):**
- `build_search_query()` - Build OpenSearch DSL from parameters
- `execute_search()` - Execute paginated search with sorting
- `extract_event_fields()` - Normalize event fields (EVTX/EDR/JSON/CSV)
- `get_event_detail()` - Retrieve single event by ID
- `format_event_for_display()` - Human-friendly key-value pairs
- `save_search_to_history()` - Persist search to database

**Event Type Detection:**
- EVTX files: Shows EventID (e.g., 4624)
- EDR/JSON files: Shows "EDR" or "JSON"
- CSV files: Shows "CSV"
- Non-EVTX JSON: Shows "JSON/CSV"

**Timeline Tags:**
- Star icon on each event row
- Click to tag/untag for timeline
- Persists in TimelineTag table
- Links to case_id, user_id, event_id, index_name
- Supports notes and color coding
- Prepared for DFIR-IRIS integration

**Column Customization:**
- Default columns: event_id, timestamp, description, computer_name
- Click "Manage Columns" to add/remove
- Add field as column from event detail modal
- Columns saved in Flask session per case
- Drag-and-drop reordering (UI support)

**Search History:**
- All searches auto-saved to database
- Shows last 10 recent searches
- Can star searches as favorites
- Favorites persist across sessions
- Click recent/favorite to re-run search

## üìã Previous Updates (2025-10-28 14:45 UTC)

### **üìù EVTX Event Descriptions System**
- **Database Model**: EventDescription table stores event_id, title, description, category, source
- **Management Page**: `/evtx_descriptions` - view and manage event descriptions database
- **Modular Scrapers**: `evtx_descriptions.py` with separate functions for each data source
- **Data Sources**: Ultimate Windows Security, GitHub Gist, Infrasos (3 sources)
- **Update Button**: Admin-only, fetches from all sources, merges into database
- **Auto-Integration**: When indexing EVTX to OpenSearch, adds event_title, event_description, event_category
- **Searchable**: Events now searchable by friendly name, not just ID
- **Pagination**: 100 events per page on management UI

**Scraper Functions (evtx_descriptions.py):**
- `scrape_ultimate_windows_security()` - 40+ common security events
- `scrape_github_gist()` - Kerberos and authentication events
- `scrape_infrasos()` - Active Directory focused events
- `update_all_descriptions(db, EventDescription)` - Main update, calls all scrapers
- `get_event_description(db, EventDescription, event_id, source)` - Lookup helper

**Integration Points:**
- `file_processing.py` ‚Üí `index_file()` - Adds descriptions during indexing
- `main.py` ‚Üí `/evtx_descriptions` - Management UI
- `main.py` ‚Üí `/evtx_descriptions/update` - Update endpoint (POST, admin-only)
- Menu item #9: Links to EVTX Descriptions management page

## üìã Previous Updates (2025-10-28 14:20 UTC)

### **üìÅ Case Files Management Page**
- **Dedicated Page**: Separate `/case/<id>/files` route with professional file management UI
- **Two-Tile Layout**: File statistics + Event statistics side-by-side
- **Bulk Operations Bar**: Centralized buttons for re-index, re-SIGMA, re-hunt IOCs, delete all
- **Detailed File Table**: Name, hash, size, **STATUS (live updates)**, events, SIGMA, IOCs, upload info, uploader
- **Live Status Updates**: Reused code from case dashboard - polls every 3 seconds during processing, 10 seconds when idle
- **Status Badges**: Completed, Indexing (pulsing), SIGMA Testing (pulsing), IOC Hunting (pulsing), Queued, Failed
- **Real-time Counts**: Event count, SIGMA violations, IOC matches update automatically
- **Pagination**: 50 files per page (default), efficient LIMIT/OFFSET queries, reusable component
- **Smart Stats**: Tiles show ALL files stats, table shows paginated subset
- **Admin Protection**: Delete all files requires administrator role
- **Data Integrity**: All bulk operations clear old data before re-processing

### **üîÑ Enhanced Bulk Operations (Reusable)**
- **bulk_reindex** (NEW): Full rebuild - clears OpenSearch indices, resets all metadata, queues full re-processing
- **bulk_rechainsaw**: Re-run SIGMA on all files - clears violations, resets counts, queues SIGMA-only processing
- **bulk_rehunt**: Re-hunt IOCs on all files - clears matches, resets counts, queues IOC-only processing
- **single_file_rehunt**: Re-hunt IOCs on single file - granular control per file
- **Data Clearing**: ALL operations clear related data BEFORE re-processing (no orphaned data)

### **üìä Case Selection Page**
- **Dedicated Route**: `/cases` - professional table view of all active cases
- **Rich Information**: Case name, company, file count, events, assignments, dates
- **Clickable Rows**: Click case ‚Üí sets session ‚Üí navigates to case dashboard
- **Session Persistence**: Selected case remembered across all pages
- **Navigation Updates**: All "no case selected" states redirect to case selection

### **‚ôªÔ∏è Reusable UI Patterns**

**Live Status Update Pattern (Used in 2+ pages):**
```javascript
// Pages: view_case_enhanced.html, case_files.html
function updateStatuses() {
    fetch(`/case/${CASE_ID}/status`)
        .then(data => {
            // For each file with data-file-id attribute:
            // 1. Update status badge (with pulsing animation if processing)
            // 2. Update event count (formatted with commas)
            // 3. Update SIGMA count (badge if > 0)
            // 4. Update IOC count (badge if > 0)
            // 5. Track processing count
        })
    // Smart polling: 3 seconds if processing, 10 seconds if idle
    setTimeout(updateStatuses, processingCount > 0 ? 3000 : 10000);
}
```

**Status Badge Classes:**
- `status-completed` - Green, no animation
- `status-indexing pulsing` - Blue, animated
- `status-sigma pulsing` - Green, animated
- `status-ioc pulsing` - Red, animated
- `status-queued` - Gray, no animation
- `status-failed` - Red, no animation

**Required HTML Structure:**
- Table rows: `<tr data-file-id="123">`
- Status cell: `<td class="status-cell">`
- Event count: `<td class="event-count">`
- SIGMA count: `<td class="sigma-count">`
- IOC count: `<td class="ioc-count">`

**Backend Endpoint:** `GET /case/<id>/status` returns JSON with file array

---

**Pagination Pattern (Reusable Component):**
```python
# Backend (main.py route pattern):
@app.route('/case/<int:case_id>/files')
def case_files(case_id):
    page = request.args.get('page', 1, type=int)
    per_page = request.args.get('per_page', 50, type=int)
    
    # Build query
    query = db.session.query(Model).filter_by(...)
    
    # Paginate (returns Pagination object)
    pagination = query.paginate(page=page, per_page=per_page, error_out=False)
    items = pagination.items
    
    # Pass to template
    return render_template('page.html', items=items, pagination=pagination)
```

```jinja
<!-- Frontend (template usage): -->
{% set endpoint = 'route_name' %}
{% include 'components/pagination.html' %}
```

**Pagination Component Features:**
- Shows: "Showing X to Y of Z files"
- Buttons: First (¬´¬´), Previous, Page Numbers, Next, Last (¬ª¬ª)
- Smart Page Display: Shows 5 pages around current, with ellipsis
- Current Page: Highlighted in primary color
- Disabled States: Grayed out when at first/last page
- Mobile Responsive: Buttons adjust for small screens

**Pagination Object Properties:**
- `pagination.items` - Current page items
- `pagination.total` - Total items count
- `pagination.page` - Current page number
- `pagination.pages` - Total pages count
- `pagination.per_page` - Items per page
- `pagination.has_prev` - Boolean
- `pagination.has_next` - Boolean
- `pagination.prev_num` - Previous page number
- `pagination.next_num` - Next page number

**Performance Benefits:**
- Reduces page load time for large datasets
- Only loads 50 files per page (default)
- Database query uses LIMIT/OFFSET efficiently
- Stats calculated once for ALL files, not per page

**Pages Using Pagination:**
1. **Case Files** (`case_files.html`) ‚úÖ 50 files/page

### **üîß Previous Updates (2025-10-27 23:35 UTC)

### **üéØ SIGMA Detection System - FULLY OPERATIONAL**
- **Chainsaw Integration**: Complete SIGMA detection workflow using Chainsaw CLI
- **Rules Management**: Automatic sync of SigmaHQ (3,877 rules) + magicsword-io/lolrmm detection rules
- **Rules Cache**: Merged rules stored at `/opt/casescope/staging/.rules-merged/` (rebuilt per run)
- **Detection Flow**:
  1. Update git repos (SigmaHQ sigma + lolrmm)
  2. Copy rules to staging cache
  3. Run `chainsaw hunt --sigma CACHE --mapping MAPPINGS --csv EVTX_FILE`
  4. Parse CSV output for violations
  5. Create/lookup `SigmaRule` entries for each unique rule
  6. Store violations in `SigmaViolation` table with proper foreign keys
  7. Update file and case violation counts
- **Performance**: ~20 seconds per EVTX file, detecting 1,200+ violations on test data

### **üêõ Critical Bug Fixes**
1. **Duplicate CaseFile Creation** ‚úÖ
   - **Issue**: `build_file_queue` created CaseFile record, then `index_file` created another
   - **Result**: Two records per file, one stuck at "Indexing", other showed incorrect data
   - **Fix**: Modified `index_file()` to accept optional `file_id` parameter and update existing record
   - **Impact**: Clean single-record-per-file workflow

2. **SIGMA Violation Storage Schema Mismatch** ‚úÖ
   - **Issue**: `SigmaViolation` model requires `rule_id` (FK to `SigmaRule`), code was passing `rule_name`
   - **Fix**: Auto-create `SigmaRule` entries for each detected rule, cache lookups, reference by `rule_id`
   - **Impact**: 1,271 violations successfully stored on test EVTX file

3. **File Processing Status Updates** ‚úÖ
   - **Issue**: Files getting stuck at "Indexing" status after successful completion
   - **Fix**: Proper status transitions through all pipeline stages
   - **Status Flow**: Queued ‚Üí Indexing ‚Üí SIGMA Hunting ‚Üí IOC Hunting ‚Üí Completed

4. **Chunked Upload Missing upload_id** ‚úÖ
   - **Issue**: JavaScript not sending `upload_id` to finalize endpoint
   - **Fix**: Generate unique `upload_id` (Date.now() + random string), include in both chunk and finalize requests
   - **Impact**: File uploads complete successfully end-to-end

---

## üìã Previous Updates (2025-10-27 20:55 UTC)

### UI/UX Enhancements
- **Enhanced System Dashboard**: 6-tile system with real-time stats (System, CaseScope, Events, Software, Recent Cases, Recent Files)
- **Enhanced Case Dashboard**: 3-tile system for individual cases
  - **Tile 1 - Case Details**: Name, ID, Description, Created Date, Created By, Assigned To, DFIR-IRIS Sync Status (click for Case Management)
  - **Tile 2 - Case Files**: Total Files, Indexed Files, Files Being Processed, Disk Space Used (click for File Management)
  - **Tile 3 - Event Stats**: Total Events, SIGMA Violations, Events w/IOCs, IOCs Tracked (click for Event Search)
- **3D Shadow Effects**: Cards have depth with hover animations
- **Light/Dark Theme**: Working theme switcher with localStorage persistence
- **Font Size Optimization**: Reduced base font from 16px to 14px for better readability
- **Tile Spacing**: Reduced internal spacing for more compact, professional appearance
- **Layout**: System Dashboard has 4 tiles across top, 2 below in 50/50 split; Case Dashboard has 3 tiles across

### System Monitoring
- **system_stats.py**: New module for real-time system monitoring
  - OS, CPU, memory, disk usage detection
  - Software version detection (Python, Flask, Celery, Redis, OpenSearch, evtx_dump, Chainsaw, Gunicorn)
  - SIGMA rules count and last update tracking
  - Case files space calculation

### Bug Fixes
- Fixed Redis version detection (redis-cli instead of redis-server)
- Fixed template logout route reference
- Fixed chunked upload finalization
- Fixed psutil dependency missing
- Database commit retry logic for locking issues

---

## üîó File Dependencies & Import Map

Understanding which files depend on which helps with debugging and refactoring:

### **Dependency Tree**

```
main.py
‚îú‚îÄ‚îÄ imports: models, config, utils, upload_integration, system_stats
‚îú‚îÄ‚îÄ imports (routes): tasks (via celery_app)
‚îî‚îÄ‚îÄ provides: app, db, User, Case, CaseFile, SigmaRule, SigmaViolation, IOC, IOCMatch, SkippedFile, opensearch_client

tasks.py
‚îú‚îÄ‚îÄ imports: file_processing, main, models, utils
‚îú‚îÄ‚îÄ uses from main: app, db, opensearch_client
‚îú‚îÄ‚îÄ uses from models: Case, CaseFile, SigmaRule, SigmaViolation, IOC, IOCMatch, SkippedFile
‚îî‚îÄ‚îÄ calls: duplicate_check(), index_file(), chainsaw_file(), hunt_iocs()

file_processing.py
‚îú‚îÄ‚îÄ imports: main (SigmaRule, Case), tasks (commit_with_retry), utils (make_index_name)
‚îú‚îÄ‚îÄ uses from main: SigmaRule, Case
‚îú‚îÄ‚îÄ calls binaries: /opt/casescope/bin/evtx_dump, /opt/casescope/bin/chainsaw
‚îî‚îÄ‚îÄ no direct imports of models (receives as parameters)

upload_pipeline.py
‚îú‚îÄ‚îÄ imports: utils
‚îú‚îÄ‚îÄ no direct imports of main/models (receives as parameters)
‚îî‚îÄ‚îÄ calls binaries: /opt/casescope/bin/evtx_dump

upload_integration.py
‚îú‚îÄ‚îÄ imports: upload_pipeline, main, models
‚îú‚îÄ‚îÄ uses from main: app, db
‚îî‚îÄ‚îÄ calls: stage functions, extract_zips, build_file_queue, filter_zero_event_files

system_stats.py
‚îú‚îÄ‚îÄ imports: main (for db access), models (for Case, CaseFile queries)
‚îî‚îÄ‚îÄ calls: system commands (via subprocess)

utils.py
‚îú‚îÄ‚îÄ no dependencies (pure utility functions)
‚îî‚îÄ‚îÄ provides: make_index_name(), hash_file_fast(), etc.

celery_app.py
‚îú‚îÄ‚îÄ imports: config
‚îî‚îÄ‚îÄ provides: celery_app instance

config.py
‚îú‚îÄ‚îÄ no dependencies (configuration only)
‚îî‚îÄ‚îÄ provides: Config class
```

### **Key Import Notes**

1. **Circular Import Prevention**: 
   - `file_processing.py` receives models as parameters instead of importing directly
   - This avoids circular dependencies with `main.py`

2. **Celery Task Isolation**:
   - `tasks.py` imports everything it needs within Flask app context
   - Worker process has access to full app state

3. **Binary Dependencies**:
   - `file_processing.py` calls: evtx_dump (EVTX‚ÜíJSON), chainsaw (SIGMA detection)
   - `upload_pipeline.py` calls: evtx_dump (event counting)

4. **External Services**:
   - `main.py` creates: opensearch_client (port 9200)
   - `celery_app.py` connects: Redis (port 6379)
   - All modules use SQLite via db session (no direct imports)

---

## üìÅ File Structure & Responsibilities

### **Core Application Files**

#### `main.py` (~950 lines)
**Purpose**: Flask app bootstrap + all routes (REFACTORING IN PROGRESS)
- App initialization
- Flask-Login setup
- OpenSearch client setup
- Context processor (auto-inject available_cases)
- **Routes:**
  - `/login` - Authentication
  - `/logout` - Logout
  - `/` - Enhanced Dashboard (system stats, cases, files, software)
  - `/case/new` - Create case
  - `/case/<id>` - View case details
  - `/case/<id>/upload` - Upload files
  - `/case/<id>/upload_chunk` - Chunked upload receiver
  - `/case/<id>/finalize_upload` - Finalize chunked upload
  - `/case/<id>/status` - API: Get file statuses (AJAX)
  - `flask init-db` - CLI command

#### `models.py` (200 lines)
**Purpose**: Database schema definitions
- `User` - User accounts & auth
- `Case` - Investigation cases
- `CaseFile` - Uploaded files metadata
  - Fields: case_id, filename, file_path, file_size, size_mb, file_hash, file_type
  - Status: indexing_status (Queued ‚Üí Indexing ‚Üí SIGMA Testing ‚Üí IOC Hunting ‚Üí Completed)
  - Counts: event_count, violation_count, ioc_event_count
- `SigmaRule` - SIGMA detection rules
- `SigmaViolation` - SIGMA detection matches
- `IOC` - Indicators of Compromise
- `IOCMatch` - IOC detection matches
- `SkippedFile` - Duplicates/zero-event files
- `SystemSettings` - Configuration
- `EventDescription` - EVTX event descriptions (NEW)
  - Fields: event_id, event_source, title, description, category, source_url, last_updated
  - Unique constraint on (event_id, event_source)
  - Used by: `file_processing.py` ‚Üí `index_file()` for friendly event names

#### `config.py`
**Purpose**: Configuration settings
- Database path
- OpenSearch connection
- Redis connection
- Secret keys
- Upload directories

#### `system_stats.py` (NEW - 230 lines)
**Purpose**: System monitoring and software version detection
- `get_system_status()` - OS, CPU, memory, disk usage
- `get_case_files_space()` - Calculate storage used by cases
- `get_software_versions()` - Detect installed software versions
- `get_service_status()` - Check systemd service health
- `get_sigma_rules_info()` - Count SIGMA rules and last update

---

## üîÑ Request Flow & Processing Pipeline

### **1. User Authentication Flow**

```
Browser ‚Üí /login (main.py)
           ‚Üì
       Check credentials (models.User)
           ‚Üì
       Set session (Flask-Login)
           ‚Üì
       Redirect to Dashboard
```

### **2. File Upload Flow**

```
Browser ‚Üí /case/<id>/upload (main.py)
           ‚Üì
       Chunked Upload JavaScript
           ‚Üì
       POST /case/<id>/upload_chunk (main.py) [multiple times]
           ‚Üì
       Saves to /opt/casescope/staging/chunks_<upload_id>/
           ‚Üì
       POST /case/<id>/finalize_upload (main.py)
           ‚Üì
       upload_integration.py: handle_chunked_upload_finalize_v96()
           ‚Üì
       upload_pipeline.py: Pipeline functions
```

### **3. Upload Pipeline Flow**

```
handle_chunked_upload_finalize_v96() [upload_integration.py]
  ‚Üì
1. Assemble chunks ‚Üí staging file
  ‚Üì
2. extract_zips_in_staging() [upload_pipeline.py]
   - Extracts ZIPs
   - Prepends ZIPNAME_ to files
   - Deletes ZIP
  ‚Üì
3. build_file_queue() [upload_pipeline.py]
   - Scans staging
   - Checks duplicates (hash + filename)
   - Creates CaseFile records (status: Queued)
  ‚Üì
4. filter_zero_event_files() [upload_pipeline.py]
   - Runs evtx_dump to count events
   - Archives 0-event files
   - Marks as hidden
  ‚Üì
5. Queue for processing
   - celery_app.send_task('tasks.process_file')
```

### **4. Worker Processing Flow**

```
Celery Worker receives task [tasks.py]
  ‚Üì
process_file(file_id, operation='full') [tasks.py]
  ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Step 1: duplicate_check()               ‚îÇ
‚îÇ File: file_processing.py                ‚îÇ
‚îÇ - Calculate SHA256 hash                 ‚îÇ
‚îÇ - Check DB for hash+filename match      ‚îÇ
‚îÇ - Skip if duplicate                     ‚îÇ
‚îÇ Status: Queued                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
  ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Step 2: index_file()                    ‚îÇ
‚îÇ File: file_processing.py                ‚îÇ
‚îÇ - Convert EVTX ‚Üí JSON (evtx_dump)      ‚îÇ
‚îÇ - Count events                          ‚îÇ
‚îÇ - Index to OpenSearch (bulk insert)    ‚îÇ
‚îÇ - Create/update CaseFile record         ‚îÇ
‚îÇ Status: Indexing                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
  ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Step 3: chainsaw_file()                 ‚îÇ
‚îÇ File: file_processing.py                ‚îÇ
‚îÇ - Update SigmaHQ rules (git pull)       ‚îÇ
‚îÇ - Update lolrmm rules (git pull)        ‚îÇ
‚îÇ - Build merged rules cache              ‚îÇ
‚îÇ - Run Chainsaw: hunt --sigma --csv      ‚îÇ
‚îÇ - Parse CSV output                      ‚îÇ
‚îÇ - Create/lookup SigmaRule entries       ‚îÇ
‚îÇ - Create SigmaViolation records         ‚îÇ
‚îÇ - Update violation counts               ‚îÇ
‚îÇ Status: SIGMA Testing ‚Üí SIGMA Hunting   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
  ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Step 4: hunt_iocs()                     ‚îÇ
‚îÇ File: file_processing.py                ‚îÇ
‚îÇ - Query OpenSearch for IOCs             ‚îÇ
‚îÇ - Create IOCMatch records               ‚îÇ
‚îÇ - Tag OpenSearch events                 ‚îÇ
‚îÇ Status: IOC Hunting                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
  ‚Üì
Mark as Completed
  ‚Üì
Update database
```

### **5. Live Status Update Flow**

```
Browser (every 3 seconds)
  ‚Üì
GET /case/<id>/status (main.py - API)
  ‚Üì
Query CaseFile table for status + counts
  ‚Üì
Return JSON
  ‚Üì
JavaScript updates DOM (no page reload)
```

---

## üìÇ File-by-File Breakdown

### **Workflow Processing Files**

#### `tasks.py` (367 lines)
**Purpose**: Celery task orchestration (REFACTORED)
**Imports**: `bulk_operations` module for all bulk operations

**Functions:**
- `commit_with_retry()` - Database commit helper
- `process_file(file_id, operation)` - **MAIN ORCHESTRATOR**
  - Calls all 4 processing steps
  - Handles status transitions
  - Error handling

**Bulk Operations (Refactored - Now use bulk_operations.py):**
- `bulk_reindex(case_id)` - Re-index all files (clears indices, DB data, re-processes)
  - Uses: `clear_case_opensearch_indices`, `clear_case_sigma_violations`, `clear_case_ioc_matches`
  - Uses: `get_case_files`, `reset_file_metadata`, `queue_file_processing`
  
- `bulk_rechainsaw(case_id)` - Re-run SIGMA on all files (clears old violations)
  - Uses: `clear_case_sigma_violations`, `get_case_files`, `queue_file_processing`
  
- `bulk_rehunt(case_id)` - Re-hunt IOCs on all files (clears old matches)
  - Uses: `clear_case_ioc_matches`, `get_case_files`, `queue_file_processing`
  
- `single_file_rehunt(file_id)` - Re-hunt IOCs on single file
  - Uses: `clear_file_ioc_matches`, `queue_file_processing`

**Status Transitions:**
- Queued ‚Üí Indexing ‚Üí SIGMA Testing ‚Üí IOC Hunting ‚Üí Completed

**Code Reuse:**
- All bulk operations now use shared functions from `bulk_operations.py`
- Eliminated 150+ lines of duplicated code
- Single source of truth for bulk operation logic

#### `evtx_descriptions.py` (350 lines)
**Purpose**: EVTX Event Description Management (NEW)
**Imports**: `requests`, `BeautifulSoup`, `datetime`, `logging`

**Functions:**
1. `scrape_ultimate_windows_security()` - Scrape Ultimate Windows Security (40+ events)
2. `scrape_github_gist()` - Scrape GitHub Gist (Kerberos events)
3. `scrape_infrasos()` - Scrape Infrasos (Active Directory events)
4. `update_all_descriptions(db, EventDescription)` - Main update function, calls all scrapers
5. `get_event_description(db, EventDescription, event_id, source)` - Lookup helper

**Data Sources:**
- https://www.ultimatewindowssecurity.com/securitylog/encyclopedia/default.aspx
- https://gist.github.com/githubfoam/69eee155e4edafb2e679fb6ac5ea47d0
- https://infrasos.com/complete-list-of-windows-event-ids-for-active-directory/

**Integration:**
- Called from: `main.py` ‚Üí `/evtx_descriptions/update` (POST)
- Used by: `file_processing.py` ‚Üí `index_file()` (adds descriptions during indexing)

#### `bulk_operations.py` (185 lines)
**Purpose**: Reusable Bulk File Operations (NEW)
**Imports**: `logging`, `typing`

**Functions:**
1. `clear_case_opensearch_indices(opensearch_client, case_id, files)` - Delete all OpenSearch indices for a case
2. `clear_case_sigma_violations(db, case_id)` - Clear all SIGMA violations for a case
3. `clear_case_ioc_matches(db, case_id)` - Clear all IOC matches for a case
4. `clear_file_sigma_violations(db, file_id)` - Clear SIGMA violations for a single file
5. `clear_file_ioc_matches(db, file_id)` - Clear IOC matches for a single file
6. `reset_file_metadata(file_obj, reset_opensearch_key)` - Reset file processing metadata
7. `get_case_files(db, case_id, include_deleted)` - Get all files for a case
8. `queue_file_processing(process_file_task, files, operation)` - Queue Celery tasks for multiple files

**Integration:**
- Used by: `tasks.py` ‚Üí `bulk_reindex`, `bulk_rechainsaw`, `bulk_rehunt`, `single_file_rehunt`
- Benefits: Eliminated 150+ lines of duplicated code, DRY principle, easier testing

#### `event_normalization.py` (195 lines)
**Purpose**: Event Field Normalization During Ingestion (NEW)
**Imports**: `datetime`, `logging`

**Functions:**
1. `normalize_event_timestamp(event)` - Extract & normalize timestamp (15+ formats)
   - EVTX: `System.TimeCreated.@attributes.SystemTime`
   - EVTX->JSON: `Event.System.TimeCreated.@attributes.SystemTime`
   - Generic: `@timestamp`, `timestamp`, `time`, `datetime`, `created_at`, etc
   - Handles: ISO 8601, Unix timestamps, date strings
   - Returns: ISO 8601 string

2. `normalize_event_computer(event)` - Extract computer/hostname (12+ field names)
   - EVTX: `System.Computer`
   - EVTX->JSON: `Event.System.Computer`
   - Generic: `hostname`, `computername`, `machine`, `device`, `agent`, etc
   - Handles: Nested dicts (e.g., `{"host": {"name": "server1"}}`)
   - Returns: Computer name string

3. `normalize_event_id(event)` - Extract event ID (6+ structures)
   - EVTX: `System.EventID` (as int or dict with #text)
   - EVTX->JSON: `Event.System.EventID`
   - Generic: `event_id`, `eventid`, `EventID`, `id`, etc
   - Returns: Event ID string

4. `normalize_event(event)` - Main function, adds 3 normalized fields
   - Adds: `normalized_timestamp`, `normalized_computer`, `normalized_event_id`
   - Called during indexing by `file_processing.py`

**Integration:**
- Called from: `file_processing.py` ‚Üí `index_file()` (line 343) for every event
- Used by: `search_utils.py` ‚Üí `extract_event_fields()` (reads normalized fields)
- Benefits: Single field lookup vs 40+ checks per event at search time

#### `file_processing.py` (950 lines)
**Purpose**: Core processing functions (modular)
**Imports**: `main` (SigmaRule, Case), `tasks` (commit_with_retry), `utils` (make_index_name), `models` (EventDescription)

**Functions:**
1. `duplicate_check(db, CaseFile, SkippedFile, case_id, filename, file_path, upload_type, exclude_file_id)`
   - Calculate SHA256 hash
   - Check database for hash+filename duplicates
   - Log to SkippedFile if duplicate
   - Returns: {'status': 'skip'|'proceed', 'file_hash': str, 'file_size': int}
   
2. `index_file(db, opensearch_client, CaseFile, Case, case_id, filename, file_path, file_hash, file_size, uploader_id, upload_type, file_id, celery_task)`
   - Detect file type (EVTX/JSON/NDJSON)
   - Convert EVTX ‚Üí JSON via `/opt/casescope/bin/evtx_dump`
   - Count events from JSONL
   - Bulk index to OpenSearch (500 docs/batch)
   - **NEW**: Update existing CaseFile record if `file_id` provided, else create new
   - Update Case aggregates (total_files, total_events)
   - Returns: {'status': 'success'|'error', 'file_id': int, 'event_count': int, 'index_name': str}
   
3. `chainsaw_file(db, opensearch_client, CaseFile, SigmaRule, SigmaViolation, file_id, index_name, celery_task)`
   - **NEW**: Clone/update SigmaHQ rules (`/opt/casescope/sigma_rules_repo/`)
   - **NEW**: Clone/update lolrmm rules (`~/lolrmm/`)
   - **NEW**: Build merged rules cache (`/opt/casescope/staging/.rules-merged/`)
   - Run Chainsaw: `/opt/casescope/bin/chainsaw hunt --sigma CACHE --mapping /opt/casescope/chainsaw/mappings/sigma-event-logs-all.yml --csv EVTX`
   - Parse CSV output (name, level, timestamp, computer, event_id, description)
   - **NEW**: Create/lookup `SigmaRule` entries for each unique rule title
   - **NEW**: Store violations with proper schema: {case_id, file_id, rule_id, event_id, event_data, matched_fields, severity}
   - Update file.violation_count
   - Update case.total_events_with_SIGMA_violations
   - Returns: {'status': 'success'|'error', 'violations': int}
   
4. `hunt_iocs(db, opensearch_client, CaseFile, IOC, IOCMatch, file_id, index_name, celery_task)`
   - Get active IOCs from database
   - Search OpenSearch for each IOC (simple_query_string, case-insensitive)
   - Create IOCMatch records
   - Update OpenSearch events (has_ioc flag)
   - Update file.ioc_event_count
   - Update case.total_events_with_IOCs
   - Returns: {'status': 'success'|'error', 'ioc_matches': int}

#### `upload_pipeline.py` (576 lines)
**Purpose**: Upload staging & preprocessing
**Functions:**
- `get_staging_path(case_id)` - Get staging directory path
- `ensure_staging_exists(case_id)` - Create staging dir
- `stage_http_upload()` - Save uploaded file to staging
- `stage_bulk_upload()` - Copy from local_uploads to staging
- `extract_zips_in_staging(case_id)` - **ZIP EXTRACTION**
  - Find all ZIPs in staging
  - Extract contents
  - Prepend ZIPNAME_ to extracted files
  - Delete ZIP after extraction
- `build_file_queue(case_id)` - **DUPLICATE CHECK**
  - Scan staging directory
  - Calculate hashes
  - Check for duplicates
  - Create CaseFile records (Queued)
  - Skip duplicates to SkippedFile
- `filter_zero_event_files(case_id)` - **ZERO-EVENT FILTER**
  - Run evtx_dump to get event count
  - Archive files with 0 events
  - Mark as hidden in database

#### `upload_integration.py` (280 lines)
**Purpose**: Bridge between routes and pipeline
**Functions:**
- `handle_http_upload_v96()` - Handle form uploads
  - Stage files
  - Extract ZIPs
  - Build queue
  - Filter zero-events
  - Send Celery tasks
  
- `handle_bulk_upload_v96()` - Handle local folder uploads
  - Stage files from local_uploads/
  - Same pipeline as HTTP
  
- `handle_chunked_upload_finalize_v96()` - **CHUNKED UPLOAD**
  - Assemble chunks
  - Run through pipeline
  - Send Celery tasks

---

## üéØ External Dependencies

### **Binaries**
- `/opt/casescope/bin/evtx_dump` - Convert EVTX to JSON
  - Used by: `file_processing.py` (index_file), `upload_pipeline.py` (filter_zero_event_files)
  - Purpose: EVTX parsing and event counting
  
- `/opt/casescope/bin/chainsaw` - SIGMA detection engine
  - Used by: `file_processing.py` (chainsaw_file)
  - Purpose: Run SIGMA rules against EVTX files
  - Mappings: `/opt/casescope/chainsaw/mappings/sigma-event-logs-all.yml`

### **External Services**
- **OpenSearch** (port 9200) - Event storage & search
  - Client created in: `main.py`
  - Used by: `file_processing.py` (index_file, hunt_iocs)
  
- **Redis** (port 6379) - Celery task queue
  - Configured in: `celery_app.py`
  - Used by: Celery worker for task distribution
  
- **SQLite** - Metadata database
  - Path: `/opt/casescope/data/casescope.db`
  - Accessed via: SQLAlchemy session in all modules

### **SIGMA Rules**
- `/opt/casescope/sigma_rules_repo/` - **SigmaHQ rules repository** (3,877 rules)
  - Cloned from: https://github.com/SigmaHQ/sigma.git
  - Used by: `file_processing.py` (chainsaw_file)
  - Windows rules: `/opt/casescope/sigma_rules_repo/rules/windows/`
  
- `~/lolrmm/` - **magicsword-io/lolrmm detection rules**
  - Cloned from: https://github.com/magicsword-io/lolrmm.git
  - Used by: `file_processing.py` (chainsaw_file)
  - SIGMA detections: `~/lolrmm/detections/sigma/`
  
- `/opt/casescope/staging/.rules-merged/` - **Merged rules cache**
  - Created by: `file_processing.py` (chainsaw_file)
  - Rebuilt on each SIGMA run for latest rules
  - Structure:
    - `sigma/` - SigmaHQ Windows rules
    - `lolrmm/` - lolrmm detection rules

---

## üìä Data Flow Summary

```
HTTP Upload ‚Üí Staging ‚Üí Extract ZIPs ‚Üí Dedupe ‚Üí Filter 0-events ‚Üí Queue
                                                                      ‚Üì
                                                                   Celery
                                                                      ‚Üì
                                    Duplicate Check ‚Üí Index ‚Üí SIGMA ‚Üí IOC ‚Üí Complete
                                                        ‚Üì        ‚Üì      ‚Üì
                                                  OpenSearch   DB     DB
```

---

## üîÑ Status Values

**File Processing Status** (`CaseFile.indexing_status`):
1. `Queued` - Waiting for worker
2. `Indexing` - Converting EVTX, indexing to OpenSearch
3. `SIGMA Testing` - Running Chainsaw detection
4. `IOC Hunting` - Searching for IOCs
5. `Completed` - All steps done
6. `Failed` - Error occurred

---

## üöÄ Planned Refactoring

### **Current State**
- `main.py` - 874 lines (TOO BIG)

### **Target State**
```
routes/
‚îú‚îÄ‚îÄ auth.py (78 lines) ‚úì CREATED
‚îú‚îÄ‚îÄ api.py (32 lines) ‚úì CREATED
‚îú‚îÄ‚îÄ dashboard.py (~150 lines) TODO
‚îú‚îÄ‚îÄ cases.py (~200 lines) TODO
‚îî‚îÄ‚îÄ files.py (~250 lines) TODO

main.py (~100 lines) - Minimal bootstrap
```

---

## üìä Enhanced Dashboard System

### **System Dashboard** (`dashboard_enhanced.html`)

The main dashboard provides comprehensive system monitoring and recent activity:

#### **1. System Status Tile** üíª
- OS Name and Version
- CPU Cores / Usage %
- Memory Total / Used (GB + %)
- Hard Disk Size / Used (GB + %)
- Space Consumed by Case Files (GB)

**Data Source**: `system_stats.get_system_status()`, `system_stats.get_case_files_space()`

#### **2. CaseScope Status Tile** üìä
All items are clickable and navigate to their respective management pages:

- **Number of Cases** ‚Üí Links to Case Selection page
- **Total Number of Files** ‚Üí Links to Global File Management (TODO)
- **Total SIGMA Rules / Enabled** ‚Üí Links to SIGMA Management (TODO)
- **SIGMA Last Updated** ‚Üí Links to SIGMA Management (TODO)
- **IOCs Globally Tracked** ‚Üí Display only

**Data Source**: Database queries, `system_stats.get_sigma_rules_info()`

#### **3. Events Status Tile** üìà
All items are clickable and navigate to Event Search page (TODO):

- **Total Number of Events** ‚Üí Searchable
- **Total SIGMA Violations Found** ‚Üí Filtered search
- **Total IOC Events Found** ‚Üí Filtered search

**Data Source**: Aggregated from `CaseFile.event_count`, `SigmaViolation`, `CaseFile.ioc_event_count`

#### **4. Software Status Tile** üõ†Ô∏è
Displays actual installed versions (not requirements):

- Python
- SQLite3
- Flask
- Celery
- Redis
- OpenSearch
- evtx_dump
- Chainsaw
- Gunicorn

**Data Source**: `system_stats.get_software_versions()`  
**Detection Method**: Subprocess calls, module imports, version parsing

#### **5. Recent Cases Section** üìÅ
- Lists last 10 cases (most recent first)
- Click on row ‚Üí Navigate to Case Dashboard
- Shows: Name, Company, File Count, Created Date
- **Empty State**: "Create First Case" CTA

#### **6. Recent Files Section** üìÑ
- Lists last 10 files uploaded
- Shows: Filename, Case, Type, Events, Status, Upload Date
- **Search Button** ‚Üí Navigate to Event Search page (TODO)

---

## üìù Quick Reference

### **Where to find...**

| What | File | Function |
|------|------|----------|
| Login page | main.py | `/login` route |
| System dashboard | main.py | `/` route |
| Case selection | main.py | `/cases` route |
| Create case | main.py | `/case/create` route |
| View case (dashboard) | main.py | `/case/<id>` route |
| **Case files page** | main.py | `/case/<id>/files` route |
| Upload UI | main.py | `/case/<id>/upload` route |
| Chunked upload receiver | main.py | `/case/<id>/upload_chunk` |
| Status API | main.py | `/case/<id>/status` |
| **Bulk re-index** | main.py | `/case/<id>/bulk_reindex` POST |
| **Bulk re-SIGMA** | main.py | `/case/<id>/bulk_rechainsaw` POST |
| **Bulk re-hunt IOCs** | main.py | `/case/<id>/bulk_rehunt_iocs` POST |
| **Bulk delete files** | main.py | `/case/<id>/bulk_delete_files` POST (admin) |
| Re-hunt single file | main.py | `/case/<id>/file/<id>/rehunt_iocs` POST |
| IOC management | routes/ioc.py | `/case/<id>/ioc/` |
| File orchestration | tasks.py | `process_file()` |
| **Bulk reindex task** | tasks.py | `bulk_reindex()` |
| **Bulk rechainsaw task** | tasks.py | `bulk_rechainsaw()` |
| **Bulk rehunt task** | tasks.py | `bulk_rehunt()` |
| **Single file rehunt** | tasks.py | `single_file_rehunt()` |
| Duplicate check | file_processing.py | `duplicate_check()` |
| EVTX indexing | file_processing.py | `index_file()` |
| SIGMA detection | file_processing.py | `chainsaw_file()` |
| IOC hunting | file_processing.py | `hunt_iocs()` |
| ZIP extraction | upload_pipeline.py | `extract_zips_in_staging()` |
| Queue building | upload_pipeline.py | `build_file_queue()` |
| Zero-event filter | upload_pipeline.py | `filter_zero_event_files()` |
| Upload handler | upload_integration.py | `handle_chunked_upload_finalize_v96()` |
| System stats | system_stats.py | `get_system_status()` |
| Software versions | system_stats.py | `get_software_versions()` |
| SIGMA rules info | system_stats.py | `get_sigma_rules_info()` |
| Case files space | system_stats.py | `get_case_files_space()` |

---

## üé® UI System & Templates

### **Template Files**

#### `templates/base.html` (Base Layout)
**Purpose**: Global layout and navigation for all pages
- Left sidebar navigation (Dashboard, SIGMA Management, Cases, Settings)
- Top header bar (case selector, theme toggle, user info, logout)
- Content block for page-specific content
- Links to `theme.css` and `app.js`

#### `templates/dashboard_enhanced.html` (System Dashboard)
**Purpose**: Main landing page with system-wide stats
- **6 Tiles Layout**:
  1. System Status (OS, CPU, Memory, Disk, Case Files Space)
  2. CaseScope Status (Cases, Files, SIGMA Rules, IOCs)
  3. Events Status (Total Events, SIGMA Violations, IOC Events)
  4. Software Status (Python, Flask, Celery, Redis, OpenSearch, etc.)
  5. Recent Cases (Last 10, clickable)
  6. Recent Files (Last 10, clickable)

#### `templates/view_case_enhanced.html` (Case Dashboard)
**Purpose**: Individual case view with 3-tile dashboard + files table
- **3 Tiles Layout**:
  1. **Case Details** (Name, ID, Description, Created Date, Created By, Assigned To, DFIR-IRIS Sync) ‚Üí Click for Case Management
  2. **Case Files** (Total Files, Indexed Files, Files Being Processed, Disk Space) ‚Üí Click for File Management
  3. **Event Stats** (Total Events, SIGMA Violations, Events w/IOCs, IOCs Tracked) ‚Üí Click for Event Search
- **Files Table**: Real-time status updates, live progress tracking
- **JavaScript**: Auto-refresh statuses every 3 seconds

#### `templates/components/stats_card.html` (Reusable Component)
**Purpose**: Reusable statistics card component

### **Static Assets**

#### `static/css/theme.css` (Global Stylesheet)
**Purpose**: Centralized styling for entire application
- **CSS Variables**: Dark theme + Light theme color palettes
- **Base Font**: 14px (reduced from 16px for better density)
- **Layout**: Sidebar, header, content containers
- **Components**: Cards, buttons, tables, badges, forms
- **3D Effects**: Drop shadows with hover animations
- **Responsive**: Mobile-friendly breakpoints

#### `static/js/app.js` (Global JavaScript)
**Purpose**: Client-side functionality
- **Theme Switching**: localStorage persistence for dark/light mode
- **Utility Functions**: formatSize, formatDate, showToast
- **Mobile**: Sidebar toggle for small screens

### **Template Route Mapping**

| Route | Template | Purpose |
|-------|----------|---------|
| `/` | `dashboard_enhanced.html` | System dashboard |
| `/cases` | `case_selection.html` | Case selection page |
| `/case/<id>` | `view_case_enhanced.html` | Case dashboard |
| `/case/<id>/files` | `case_files.html` | Case files management (paginated) |
| `/case/<id>/search` | `search_events.html` | Advanced event search (NEW v1.4.0) |
| `/case/<id>/upload` | `upload_files.html` | Chunked file upload |
| `/case/<id>/iocs` | `ioc_management.html` | IOC management |
| `/evtx_descriptions` | `evtx_descriptions.html` | EVTX event descriptions |
| `/sigma` | `sigma_management.html` | SIGMA rules management |
| `/login` | `login.html` | Authentication |

---

## üîß Configuration Files

- `/etc/systemd/system/casescope.service` - Web service
- `/etc/systemd/system/casescope-worker.service` - Celery worker
- `/opt/casescope/app/config.py` - App configuration
- `/opt/casescope/app/celery_app.py` - Celery configuration

---

## üìÇ Directory Structure

```
/opt/casescope/
‚îú‚îÄ‚îÄ app/              # Application code
‚îú‚îÄ‚îÄ venv/             # Python virtual environment
‚îú‚îÄ‚îÄ data/             # SQLite database
‚îú‚îÄ‚îÄ uploads/          # Final file storage (by case_id)
‚îú‚îÄ‚îÄ staging/          # Temporary upload staging
‚îú‚îÄ‚îÄ archive/          # Zero-event files
‚îú‚îÄ‚îÄ local_uploads/    # Bulk upload folder
‚îú‚îÄ‚îÄ logs/             # Application logs
‚îú‚îÄ‚îÄ bin/              # Binaries (evtx_dump, chainsaw)
‚îú‚îÄ‚îÄ sigma_rules/      # Symlink to rules
‚îú‚îÄ‚îÄ sigma_rules_repo/ # SigmaHQ repository clone
‚îî‚îÄ‚îÄ chainsaw/         # Chainsaw mappings
```

---

**This map will be updated as refactoring progresses.**
